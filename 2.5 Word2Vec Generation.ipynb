{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from annoy import AnnoyIndex\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.autonotebook import tqdm\n",
    "tqdm.pandas()\n",
    "import gc\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True, use_memory_fs=False)\n",
    "#Config\n",
    "GENERATE_FOR = \"kaggle\"\n",
    "TRAIN = True # set True if you want to train the w2vec model from scratch\n",
    "VECTOR_SIZE = 32\n",
    "CANDIDATES = 100\n",
    "DISK_PIECES = 4\n",
    "VER = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE_FOR == \"local\":\n",
    "    train_df = pl.concat([pl.read_parquet(\"./splitted_raw_data/train.parquet\"),pl.read_parquet(\"./splitted_raw_data/val.parquet\")])\n",
    "if GENERATE_FOR == \"kaggle\":\n",
    "    train_df = pl.concat([pl.read_parquet('./splitted_raw_data/all_train.parquet'),pl.read_parquet(\"./splitted_raw_data/test.parquet\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now transform the data into a format that the `gensim` library can work with. Thanks to `polars` we can do so very efficiently and very quickly.\n",
    "\n",
    "There are various ways we could feed our data to our model, however doing so straight from RAM in the form of Python lists is probably one of the fastest! As we have enough resources on Kaggle to do so, let us take this approach!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T20:28:28.087746Z",
     "iopub.status.busy": "2023-01-06T20:28:28.087379Z",
     "iopub.status.idle": "2023-01-06T20:51:27.895542Z",
     "shell.execute_reply": "2023-01-06T20:51:27.894453Z",
     "shell.execute_reply.started": "2023-01-06T20:28:28.087714Z"
    }
   },
   "outputs": [],
   "source": [
    "#word2vec train\n",
    "if TRAIN:\n",
    "    sentences_df = train_df.groupby('session').agg(pl.col('aid').alias('sentence'))\n",
    "    sentences = sentences_df['sentence'].to_list()\n",
    "    del sentences_df; gc.collect()\n",
    "    print('Word2Vec training started...')\n",
    "    w2vec = Word2Vec(sentences=sentences, vector_size=VECTOR_SIZE, min_count=1,window=20, workers=-1) # workers: kaggle nb'de çalıştırcaksan workers ayarla\n",
    "    print('Word2Vec training, done.')\n",
    "    wv = w2vec.wv\n",
    "    wv.save(f\"./models/word2vec_{GENERATE_FOR}.wordvectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T20:51:35.862482Z",
     "iopub.status.busy": "2023-01-06T20:51:35.862148Z",
     "iopub.status.idle": "2023-01-06T20:51:35.872009Z",
     "shell.execute_reply": "2023-01-06T20:51:35.870682Z",
     "shell.execute_reply.started": "2023-01-06T20:51:35.862450Z"
    }
   },
   "outputs": [],
   "source": [
    "aids = train_df.select(pl.col('aid').unique())['aid'].to_list()\n",
    "len(aids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T20:53:47.785988Z",
     "iopub.status.busy": "2023-01-06T20:53:47.785565Z",
     "iopub.status.idle": "2023-01-06T20:53:47.791712Z",
     "shell.execute_reply": "2023-01-06T20:53:47.790380Z",
     "shell.execute_reply.started": "2023-01-06T20:53:47.785953Z"
    }
   },
   "outputs": [],
   "source": [
    "if TRAIN == False:\n",
    "    wv = KeyedVectors.load(f\"./models/word2vec_{GENERATE_FOR}.wordvectors\", mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T20:53:55.827482Z",
     "iopub.status.busy": "2023-01-06T20:53:55.826456Z",
     "iopub.status.idle": "2023-01-06T20:54:05.590027Z",
     "shell.execute_reply": "2023-01-06T20:54:05.588954Z",
     "shell.execute_reply.started": "2023-01-06T20:53:55.827442Z"
    }
   },
   "outputs": [],
   "source": [
    "#vector extraction\n",
    "from tqdm import tqdm\n",
    "vectors = []\n",
    "for aid in tqdm(aids):\n",
    "    vectors.append(wv[aid].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T20:54:05.592360Z",
     "iopub.status.busy": "2023-01-06T20:54:05.592035Z",
     "iopub.status.idle": "2023-01-06T20:54:17.351243Z",
     "shell.execute_reply": "2023-01-06T20:54:17.350019Z",
     "shell.execute_reply.started": "2023-01-06T20:54:05.592330Z"
    }
   },
   "outputs": [],
   "source": [
    "aid_vectors = pd.concat([pd.Series(aids,name='aid'),pd.Series(vectors,name='vectors')],axis=1)\n",
    "aid_vectors.to_parquet(f'./all_features/{GENERATE_FOR}_w2v_aid_vectors.pqt')\n",
    "del aid_vectors,vectors;gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximate NN for Similarity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T20:54:17.353620Z",
     "iopub.status.busy": "2023-01-06T20:54:17.352912Z",
     "iopub.status.idle": "2023-01-06T20:54:53.441742Z",
     "shell.execute_reply": "2023-01-06T20:54:53.440027Z",
     "shell.execute_reply.started": "2023-01-06T20:54:17.353570Z"
    }
   },
   "outputs": [],
   "source": [
    "#annoy indexing\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "aid2idx = {aid: i for i, aid in enumerate(wv.index_to_key)}\n",
    "annoy = AnnoyIndex(VECTOR_SIZE, 'euclidean')\n",
    "\n",
    "for aid, idx in aid2idx.items():\n",
    "    annoy.add_item(idx, wv.vectors[idx])\n",
    "    \n",
    "annoy.build(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T20:55:42.656003Z",
     "iopub.status.busy": "2023-01-06T20:55:42.655507Z",
     "iopub.status.idle": "2023-01-06T20:55:55.407277Z",
     "shell.execute_reply": "2023-01-06T20:55:55.406144Z",
     "shell.execute_reply.started": "2023-01-06T20:55:42.655964Z"
    }
   },
   "outputs": [],
   "source": [
    "aid_vectors = pd.read_parquet(f'./all_features/{GENERATE_FOR}_w2v_aid_vectors.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T20:55:55.410509Z",
     "iopub.status.busy": "2023-01-06T20:55:55.409935Z",
     "iopub.status.idle": "2023-01-06T20:55:55.436034Z",
     "shell.execute_reply": "2023-01-06T20:55:55.435061Z",
     "shell.execute_reply.started": "2023-01-06T20:55:55.410458Z"
    }
   },
   "outputs": [],
   "source": [
    "aid_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T20:55:55.438608Z",
     "iopub.status.busy": "2023-01-06T20:55:55.437545Z",
     "iopub.status.idle": "2023-01-06T20:55:55.446127Z",
     "shell.execute_reply": "2023-01-06T20:55:55.444925Z",
     "shell.execute_reply.started": "2023-01-06T20:55:55.438564Z"
    }
   },
   "outputs": [],
   "source": [
    "def annoy_get_distance(aid1,aid2,aid2idx,annoy):\n",
    "    return annoy.get_distance(aid2idx[aid1], aid2idx[aid2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T20:58:49.831471Z",
     "iopub.status.busy": "2023-01-06T20:58:49.830542Z",
     "iopub.status.idle": "2023-01-06T21:03:47.171078Z",
     "shell.execute_reply": "2023-01-06T21:03:47.166545Z",
     "shell.execute_reply.started": "2023-01-06T20:58:49.831431Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "data_dir = Path(f\"../raw_data/{GENERATE_FOR}_covisitation\") #covisitation path\n",
    "for type_str in tqdm(['clicks','carts','buy2buy']): # types\n",
    "    part = 0\n",
    "    whole_out_df = []\n",
    "    for pqt_file in tqdm(sorted(data_dir.glob(f'{GENERATE_FOR}_top_{CANDIDATES}_{type_str}*'))):\n",
    "        print(pqt_file)\n",
    "        temp_df = pd.read_parquet(pqt_file)\n",
    "        display(temp_df)\n",
    "        similarities = []\n",
    "        temp_df['similarity'] = temp_df.parallel_apply(lambda x: annoy_get_distance(x['aid_x'],x['aid_y'],aid2idx,annoy),axis=1)\n",
    "        whole_out_df.append(temp_df)\n",
    "        part += 1\n",
    "        del temp_df; gc.collect()\n",
    "    whole_out_df = pd.concat(whole_out_df, ignore_index=True)\n",
    "    whole_out_df.to_parquet(f'./all_features/{GENERATE_FOR}_top_{CANDIDATES}_{type_str}_w2v_similarities.pqt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
