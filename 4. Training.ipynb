{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19803c5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-28T18:49:25.672561Z",
     "iopub.status.busy": "2022-11-28T18:49:25.671835Z",
     "iopub.status.idle": "2022-11-28T18:49:28.346781Z",
     "shell.execute_reply": "2022-11-28T18:49:28.345442Z"
    },
    "papermill": {
     "duration": 2.696152,
     "end_time": "2022-11-28T18:49:28.349900",
     "exception": false,
     "start_time": "2022-11-28T18:49:25.653748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "VER = 6\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import os, sys, pickle, glob, gc\n",
    "from collections import Counter\n",
    "import cudf, itertools\n",
    "print('We will use RAPIDS version',cudf.__version__)\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import polars as pl\n",
    "\n",
    "from pyarrow.parquet import ParquetFile\n",
    "import pyarrow as pa \n",
    "from fastai.tabular.core import df_shrink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adb89d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_negative_session(df,target='label'):\n",
    "    true_df = df.groupby('session')[target].agg('sum') > 0\n",
    "    session = pd.DataFrame(true_df[true_df]).reset_index()['session']\n",
    "    df = df.merge(session, how = 'inner', on = 'session')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2505537",
   "metadata": {
    "papermill": {
     "duration": 0.020472,
     "end_time": "2022-11-28T18:57:43.433117",
     "exception": false,
     "start_time": "2022-11-28T18:57:43.412645",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70b81b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_labels = {'clicks':0, 'carts':1, 'orders':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf01ab42",
   "metadata": {},
   "outputs": [],
   "source": [
    "CANDIDATE_COUNT = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d11bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sessions = np.load(\"./splitted_raw_data/val_sessions_for_train.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438cd4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_iters = {\n",
    "    'clicks': 900,\n",
    "    'carts': 400,\n",
    "    'orders': 400\n",
    "}\n",
    "\n",
    "type_fracs = {\n",
    "    'clicks': 0.15,\n",
    "    'carts': 0.15,\n",
    "    'orders': 0.15\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988d59c2",
   "metadata": {},
   "source": [
    "## For each action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede33468",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostRanker, Pool, MetricVisualizer\n",
    "\n",
    "model_iters = {}\n",
    "\n",
    "for type_str in tqdm(list(type_labels.keys())):\n",
    "\n",
    "    whole_df = []\n",
    "    batches = sorted(glob.glob(f\"./candidated_features/local_{type_str}_all_data_{CANDIDATE_COUNT}candidates_p*.pqt\"))\n",
    "    \n",
    "    for batch in tqdm(batches):\n",
    "        \n",
    "        batch = pd.read_parquet(batch)\n",
    "        batch = remove_negative_session(batch)\n",
    "        batch = batch[batch.session.isin(train_sessions)].reset_index(drop=True)\n",
    "        positives = batch.loc[batch['label']==1].copy()\n",
    "        negatives = batch.loc[batch['label']==0].groupby(\"session\").sample(frac=type_fracs[type_str],\n",
    "                                                                           random_state=1337)\n",
    "        whole_df.append(positives)\n",
    "        whole_df.append(negatives)\n",
    "        del batch, positives, negatives\n",
    "        \n",
    "    whole_df = pd.concat(whole_df, axis=0, ignore_index=True)\n",
    "    \n",
    "    print(f\"sampled: {whole_df.shape}\")\n",
    "\n",
    "    FEATURES = whole_df.columns[2 : -1]   \n",
    "    \n",
    "    whole_df = whole_df.sort_values('session').reset_index(drop=True)\n",
    "    \n",
    "    skf = GroupKFold(n_splits=5)\n",
    "    for fold, (train_idx, valid_idx) in enumerate(skf.split(whole_df,\n",
    "                                                            whole_df['label'],\n",
    "                                                            groups=whole_df['session'])):\n",
    "        X_train = whole_df.loc[train_idx, FEATURES]\n",
    "        y_train = whole_df.loc[train_idx, 'label']\n",
    "        X_valid = whole_df.loc[valid_idx, FEATURES]\n",
    "        y_valid = whole_df.loc[valid_idx, 'label']\n",
    "\n",
    "        train_groups = whole_df.loc[train_idx].groupby('session', sort=False)[\"session\"].agg('count').values\n",
    "        val_groups = whole_df.loc[valid_idx].groupby('session', sort=False)[\"session\"].agg('count').values\n",
    "        \n",
    "\n",
    "        dtrain = xgb.DMatrix(X_train, y_train, group = train_groups) \n",
    "        dtest = xgb.DMatrix(X_valid, y_valid, group = val_groups) \n",
    "\n",
    "        xgb_parms = {'objective':'rank:pairwise',\n",
    "                     'tree_method':'gpu_hist',\n",
    "                    \"random_state\":42, \n",
    "                    \"learning_rate\":0.1,\n",
    "                    \"colsample_bytree\":0.9, \n",
    "                    \"eta\":0.05, \n",
    "                    \"max_depth\":6, \n",
    "                    \"subsample\":0.9,\n",
    "                    }\n",
    "        model = xgb.train(xgb_parms,\n",
    "                          dtrain=dtrain,\n",
    "                          evals=[(dtrain,'train'),(dtest,'valid')],\n",
    "                          num_boost_round = type_iters[type_str],\n",
    "                          verbose_eval=100)\n",
    "\n",
    "    \n",
    "        \n",
    "        model_path = f'./models/XGB_{CANDIDATE_COUNT}candidates_fold{fold}_{type_str}.xgb'\n",
    "        model.save_model(model_path)\n",
    "        \n",
    "        model_iters[model_path] = model.best_ntree_limit\n",
    "        \n",
    "        del model, X_train, y_train, X_valid, y_valid, dtrain, dtest\n",
    "        \n",
    "        for i in range(5):\n",
    "            gc.collect()\n",
    "            \n",
    "    del whole_df\n",
    "    for i in range(5):\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb48cf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./models/model_iters.json', 'w') as fp:\n",
    "    json.dump(model_iters, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3695.647257,
   "end_time": "2022-11-28T19:50:53.428271",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-11-28T18:49:17.781014",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
