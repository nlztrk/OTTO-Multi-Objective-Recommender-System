{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19803c5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-28T18:49:25.672561Z",
     "iopub.status.busy": "2022-11-28T18:49:25.671835Z",
     "iopub.status.idle": "2022-11-28T18:49:28.346781Z",
     "shell.execute_reply": "2022-11-28T18:49:28.345442Z"
    },
    "papermill": {
     "duration": 2.696152,
     "end_time": "2022-11-28T18:49:28.349900",
     "exception": false,
     "start_time": "2022-11-28T18:49:25.653748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will use RAPIDS version 22.10.00a+392.g1558403753\n",
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "VER = 6\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import os, sys, pickle, glob, gc\n",
    "from collections import Counter\n",
    "import cudf, itertools\n",
    "print('We will use RAPIDS version',cudf.__version__)\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "pandarallel.initialize(nb_workers=4, progress_bar=True, use_memory_fs=True)\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "from pyarrow.parquet import ParquetFile\n",
    "import pyarrow as pa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da36dbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory(df):\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type != object:\n",
    "            cmin = df[col].min()\n",
    "            cmax = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if cmin > np.iinfo(np.int32).min and cmax < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif cmin > np.iinfo(np.int64).min and cmax < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if cmin > np.finfo(np.float32).min and cmax < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2505537",
   "metadata": {
    "papermill": {
     "duration": 0.020472,
     "end_time": "2022-11-28T18:57:43.433117",
     "exception": false,
     "start_time": "2022-11-28T18:57:43.412645",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15a31502",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE_FOR = \"kaggle\" # \"kaggle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e70b81b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_labels = {'clicks':0, 'carts':1, 'orders':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df7c530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CANDIDATE_COUNT = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfedd66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE_FOR == \"local\":\n",
    "    train_path = \"./splitted_raw_data/train.parquet\"\n",
    "    val_path = \"./splitted_raw_data/val.parquet\"\n",
    "    \n",
    "elif GENERATE_FOR == \"kaggle\":\n",
    "    train_path = \"./splitted_raw_data/all_train.parquet\"\n",
    "    val_path = \"./splitted_raw_data/test.parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d255fb05",
   "metadata": {},
   "source": [
    "### CANDIDATE COVISIT FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "119fee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_covisitation_features(input_cand_df,\n",
    "                              input_user_int_df,\n",
    "                              input_covisit_df,\n",
    "                              covisit_name=\"clicks\",\n",
    "                              score_col=\"wgt\",\n",
    "                              scoring_name=\"covisitation\",\n",
    "                              session_history_wanted_types=None):      \n",
    "    \n",
    "    if session_history_wanted_types:\n",
    "        filtered_input_user_int_df = input_user_int_df.filter(pl.col('type').is_in(session_history_wanted_types))\n",
    "    else: \n",
    "        filtered_input_user_int_df = input_user_int_df\n",
    "    \n",
    "    candidates_w_covisit = input_cand_df[[\"session\", \"aid\"]].rename({\"aid\":\"aid_x\"}).\\\n",
    "    join(filtered_input_user_int_df.rename({\"aid\":\"aid_y\"})[[\"session\", \"aid_y\"]],\n",
    "         how=\"left\",\n",
    "         on=\"session\").fill_null(0).join(input_covisit_df, how=\"left\", on=[\"aid_x\", \"aid_y\"])\n",
    "\n",
    "    candidates_w_covisit = candidates_w_covisit.fill_null(0.)\n",
    "    \n",
    "    candidates_w_covisit_gby = (\n",
    "        candidates_w_covisit\n",
    "        .groupby([\"session\", \"aid_x\"])\n",
    "        .agg(\n",
    "            [\n",
    "                pl.col(score_col).max().alias(covisit_name + '_' + scoring_name + '_' + \"max\"),\n",
    "                pl.col(score_col).min().alias(covisit_name + '_' + scoring_name + '_' + \"min\"),\n",
    "                pl.col(score_col).std().alias(covisit_name + '_' + scoring_name + '_' + \"std\"),\n",
    "                pl.col(score_col).sum().alias(covisit_name + '_' + scoring_name + '_' + \"sum\"),\n",
    "                pl.col(score_col).mean().alias(covisit_name + '_' + scoring_name + '_' + \"mean\"),\n",
    "                pl.col(score_col).count().alias(covisit_name + '_' + scoring_name + '_' + \"count\"),\n",
    "            ]\n",
    "        )\n",
    "    ).sort(\"session\", reverse=False)\n",
    "\n",
    "    candidates_w_covisit_gby = candidates_w_covisit_gby.rename({\"aid_x\":\"aid\"})\n",
    "    \n",
    "    candidates_w_covisit_gby = candidates_w_covisit_gby.with_column(pl.col(\"aid\").cast(pl.Int32))\n",
    "    candidates_w_covisit_gby = candidates_w_covisit_gby.with_column(pl.col(\"session\").cast(pl.Int32)) \n",
    "    return candidates_w_covisit_gby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "977affcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidate_history_pair_score_features(input_val_df_path,\n",
    "                                                   score_df_tuples_w_names,\n",
    "                                                   score_col,\n",
    "                                                   scoring_name=\"covisitation\"):\n",
    "    \n",
    "    val_df = pl.read_parquet(input_val_df_path)\n",
    "\n",
    "    for type_str in tqdm(list(type_labels.keys())):\n",
    "\n",
    "        pf = ParquetFile(f\"./candidate_data/{GENERATE_FOR}_{CANDIDATE_COUNT}candidates_{type_str}.parquet\")\n",
    "        chunk = 10_000_000\n",
    "\n",
    "        total_candidate_df = []\n",
    "\n",
    "        for batch_i, batch in tqdm(enumerate(pf.iter_batches(batch_size = chunk))):\n",
    "            candidate_df = batch.to_pandas()\n",
    "            del batch\n",
    "            candidate_df = pl.from_pandas(candidate_df)\n",
    "\n",
    "            candidate_df = candidate_df.with_column(pl.col(\"aid\").cast(pl.Int32))\n",
    "            candidate_df = candidate_df.with_column(pl.col(\"session\").cast(pl.Int32)) \n",
    "\n",
    "            val_df = val_df.with_column(pl.col(\"aid\").cast(pl.Int32))\n",
    "            val_df = val_df.with_column(pl.col(\"session\").cast(pl.Int32))\n",
    "\n",
    "            for covisit in score_df_tuples_w_names:\n",
    "                covisit[0] = covisit[0].with_column(pl.col(\"aid_x\").cast(pl.Int32))\n",
    "                covisit[0] = covisit[0].with_column(pl.col(\"aid_y\").cast(pl.Int32))\n",
    "\n",
    "                candidate_df = candidate_df.join(\n",
    "                    get_covisitation_features(input_cand_df=candidate_df,\n",
    "                                              input_user_int_df=val_df,\n",
    "                                              input_covisit_df=covisit[0],\n",
    "                                              covisit_name=covisit[1],\n",
    "                                              score_col=score_col,\n",
    "                                              scoring_name=scoring_name,\n",
    "                                              session_history_wanted_types=covisit[2]),\n",
    "                    how=\"left\",\n",
    "                    on=[\"session\", \"aid\"])\n",
    "\n",
    "            candidate_df = candidate_df.with_column(pl.col(\"aid\").cast(pl.Int64))\n",
    "            candidate_df = candidate_df.with_column(pl.col(\"session\").cast(pl.Int64))         \n",
    "\n",
    "            total_candidate_df.append(candidate_df)\n",
    "\n",
    "            del candidate_df\n",
    "\n",
    "        total_candidate_df = pl.concat(total_candidate_df)    \n",
    "        \n",
    "        total_candidate_df = total_candidate_df.with_columns([pl.col(total_candidate_df.columns[2:]).cast(pl.Float32),])\n",
    "        total_candidate_df.write_parquet(f'../raw_data/{GENERATE_FOR}_{scoring_name}_features/{scoring_name}_features_{type_str}_{CANDIDATE_COUNT}candidates.pqt')\n",
    "\n",
    "        del total_candidate_df;gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b24d90",
   "metadata": {},
   "source": [
    "### Covisitation pair 'wgt' features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9fdc52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading clicks covisitation...\n",
      "Reading carts-orders covisitation...\n",
      "Reading buy2buy covisitation...\n"
     ]
    }
   ],
   "source": [
    "DISK_PIECES = 4\n",
    "\n",
    "print(\"Reading clicks covisitation...\")\n",
    "clicks_cov_df = pl.from_pandas(pd.concat([pd.read_parquet(f'../raw_data/{GENERATE_FOR}_covisitation/{GENERATE_FOR}_top_{CANDIDATE_COUNT}_clicks_v{VER}_{k}.pqt') for k in range(0, DISK_PIECES)], ignore_index=True))\n",
    "print(\"Reading carts-orders covisitation...\")\n",
    "carts_orders_cov_df = pl.from_pandas(pd.concat([pd.read_parquet(f'../raw_data/{GENERATE_FOR}_covisitation/{GENERATE_FOR}_top_{CANDIDATE_COUNT}_carts_orders_v{VER}_{k}.pqt') for k in range(0, DISK_PIECES)], ignore_index=True))\n",
    "print(\"Reading buy2buy covisitation...\")\n",
    "buy2buy_cov_df = pl.from_pandas(pd.concat([pd.read_parquet(f'../raw_data/{GENERATE_FOR}_covisitation/{GENERATE_FOR}_top_{CANDIDATE_COUNT}_buy2buy_v{VER}_{k}.pqt') for k in range(0, 1)], ignore_index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bda6f7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_covisits_features(input_covisit_df,\n",
    "                         score_col,\n",
    "                         covisit_name):\n",
    "    aid_cov_feat_df = (\n",
    "        clicks_cov_df\n",
    "        .groupby([\"aid_x\"])\n",
    "        .agg(\n",
    "            [\n",
    "                pl.col(score_col).max().alias(covisit_name + '_' + score_col + '_' + \"max\"),\n",
    "                pl.col(score_col).min().alias(covisit_name + '_' + score_col + '_' + \"min\"),\n",
    "                pl.col(score_col).std().alias(covisit_name + '_' + score_col + '_' + \"std\"),\n",
    "                pl.col(score_col).sum().alias(covisit_name + '_' + score_col + '_' + \"sum\"),\n",
    "                pl.col(score_col).mean().alias(covisit_name + '_' + score_col + '_' + \"mean\"),\n",
    "                pl.col(score_col).count().alias(covisit_name + '_' + score_col + '_' + \"count\"),\n",
    "            ]\n",
    "        )\n",
    "    ).sort(\"aid_x\", reverse=False).rename({\"aid_x\":\"aid\"})\n",
    "    \n",
    "    aid_cov_feat_df = aid_cov_feat_df.with_columns([pl.col([\"aid\"]).cast(pl.Int64)])\n",
    "\n",
    "    aid_cov_feat_df.write_parquet(f'../raw_data/{GENERATE_FOR}_covisitation_features/{covisit_name}_covisitation_features.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57d205bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "513bd56371f349af92df81d4a2f004dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score_df_tuples_w_names = [[clicks_cov_df, \"all_clicks\"],\n",
    "                           [carts_orders_cov_df, \"all_carts_orders\"],\n",
    "                           [buy2buy_cov_df, \"all_buy2buy\"]]\n",
    "\n",
    "for covisit_tuple in tqdm(score_df_tuples_w_names):\n",
    "    all_covisits_features(input_covisit_df=covisit_tuple[0],\n",
    "                          score_col=\"wgt\",\n",
    "                          covisit_name=covisit_tuple[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d15db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df_tuples_w_names = [[clicks_cov_df, \"clicks\", None],\n",
    "                           [carts_orders_cov_df, \"carts_orders\", None],\n",
    "                           [buy2buy_cov_df, \"buy2buy\", None]]\n",
    "\n",
    "generate_candidate_history_pair_score_features(input_val_df_path=val_path,\n",
    "                                               score_df_tuples_w_names=score_df_tuples_w_names,\n",
    "                                               score_col=\"wgt\",\n",
    "                                               scoring_name=\"covisitation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baf8c84",
   "metadata": {},
   "source": [
    "### Word2Vec pair 'similarity' features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2b8e49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading clicks w2v...\n",
      "Reading carts-orders w2v...\n",
      "Reading buy2buy w2v...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87bd4c4e6f804f6490c902e930756441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea2bb49f1c34ba3a1ebb1b2edaebd7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61dab9028e074e2e80bc2ee52feda9a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb68d865b8e848c186367ab69e3d50a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Reading clicks w2v...\")\n",
    "clicks_cov_df = pl.scan_parquet(f'./all_features/{GENERATE_FOR}_top_{CANDIDATE_COUNT}_clicks_w2v_similarities.pqt')\n",
    "clicks_cov_df = clicks_cov_df.rename({\"similarity\":\"w2v_similarity\"})\n",
    "print(\"Reading carts-orders w2v...\")\n",
    "carts_orders_cov_df = pl.scan_parquet(f'./all_features/{GENERATE_FOR}_top_{CANDIDATE_COUNT}_carts_w2v_similarities.pqt')\n",
    "carts_orders_cov_df = carts_orders_cov_df.rename({\"similarity\":\"w2v_similarity\"})\n",
    "print(\"Reading buy2buy w2v...\")\n",
    "buy2buy_cov_df = pl.scan_parquet(f'./all_features/{GENERATE_FOR}_top_{CANDIDATE_COUNT}_buy2buy_w2v_similarities.pqt')\n",
    "buy2buy_cov_df = buy2buy_cov_df.rename({\"similarity\":\"w2v_similarity\"})\n",
    "\n",
    "score_df_tuples_w_names = [[clicks_cov_df, \"clicks\", None],\n",
    "                           [carts_orders_cov_df, \"carts_orders\", None],\n",
    "                           [buy2buy_cov_df, \"buy2buy\", None]]\n",
    "\n",
    "generate_candidate_history_pair_score_features(input_val_df_path=val_path,\n",
    "                                               score_df_tuples_w_names=score_df_tuples_w_names,\n",
    "                                               score_col=\"w2v_similarity\",\n",
    "                                               scoring_name=\"word2vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988d59c2",
   "metadata": {},
   "source": [
    "## Generating Feature Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffa48ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_datetime_features(input_df):\n",
    "    input_df[\"datetime\"] = pd.to_datetime(input_df.ts + (2 * 60 * 60), unit='s')\n",
    "    input_df[\"hour\"] = input_df[\"datetime\"].dt.hour\n",
    "    input_df[\"dayofweek\"] = input_df[\"datetime\"].dt.dayofweek\n",
    "    input_df[\"is_weekend\"] = (input_df[\"dayofweek\"]>4).astype(int)\n",
    "    return input_df\n",
    "\n",
    "train_df = pd.read_parquet(train_path)\n",
    "val_df = pd.read_parquet(val_path)\n",
    "\n",
    "train_df = generate_datetime_features(train_df)\n",
    "val_df = generate_datetime_features(val_df)\n",
    "\n",
    "item_df = pd.concat([train_df,val_df], ignore_index=True)\n",
    "user_df = val_df\n",
    "user_item_int_df = val_df    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d47b300",
   "metadata": {},
   "source": [
    "### Extract AID-Type Occurence Counts & Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98010e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aid</th>\n",
       "      <th>click_count</th>\n",
       "      <th>cart_count</th>\n",
       "      <th>order_count</th>\n",
       "      <th>click_prob</th>\n",
       "      <th>cart_prob</th>\n",
       "      <th>order_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.387898e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.641680e-07</td>\n",
       "      <td>5.725343e-08</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.457140e-08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2513</td>\n",
       "      <td>205.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.250164e-05</td>\n",
       "      <td>1.173695e-05</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>212</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.054655e-06</td>\n",
       "      <td>5.152809e-07</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   aid  click_count  cart_count  order_count    click_prob     cart_prob  \\\n",
       "0    0           48         0.0          0.0  2.387898e-07  0.000000e+00   \n",
       "1    1           33         1.0          0.0  1.641680e-07  5.725343e-08   \n",
       "2    2           17         0.0          0.0  8.457140e-08  0.000000e+00   \n",
       "3    3         2513       205.0         41.0  1.250164e-05  1.173695e-05   \n",
       "4    4          212         9.0          0.0  1.054655e-06  5.152809e-07   \n",
       "\n",
       "   order_prob  \n",
       "0    0.000000  \n",
       "1    0.000000  \n",
       "2    0.000000  \n",
       "3    0.000008  \n",
       "4    0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aid_count_df = item_df[item_df.type==0].groupby(\"aid\")[\"ts\"].count().rename(\"click_count\").to_frame().reset_index()\n",
    "aid_cart_df = item_df[item_df.type==1].groupby(\"aid\")[\"ts\"].count().rename(\"cart_count\").to_frame().reset_index()\n",
    "aid_order_df = item_df[item_df.type==2].groupby(\"aid\")[\"ts\"].count().rename(\"order_count\").to_frame().reset_index()\n",
    "\n",
    "aid_count_df = aid_count_df.merge(aid_cart_df, how=\"left\", on=\"aid\")\n",
    "aid_count_df = aid_count_df.merge(aid_order_df, how=\"left\", on=\"aid\")\n",
    "\n",
    "aid_count_df.fillna(0., inplace=True)\n",
    "\n",
    "aid_count_df[\"click_prob\"] = aid_count_df[\"click_count\"] / aid_count_df[\"click_count\"].sum()\n",
    "aid_count_df[\"cart_prob\"] = aid_count_df[\"cart_count\"] / aid_count_df[\"cart_count\"].sum()\n",
    "aid_count_df[\"order_prob\"] = aid_count_df[\"order_count\"] / aid_count_df[\"order_count\"].sum()\n",
    "\n",
    "aid_count_df.to_parquet(f'./all_features/{GENERATE_FOR}_aid_occurences.pqt')\n",
    "\n",
    "display(aid_count_df.head())\n",
    "\n",
    "del aid_count_df, aid_order_df, aid_cart_df; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826d96f6",
   "metadata": {},
   "source": [
    "### Co-Occurence Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12d38760",
   "metadata": {},
   "outputs": [],
   "source": [
    "co_order_v_order = sorted(glob.glob(f\"../raw_data/{GENERATE_FOR}_cooccurence/{GENERATE_FOR}_(orders)vs(orders)_cooccurences_v10_*.pqt\"))\n",
    "co_order_v_order = pd.concat([pd.read_parquet(f) for f in co_order_v_order], ignore_index=True)\n",
    "\n",
    "co_cart_v_cart = sorted(glob.glob(f\"../raw_data/{GENERATE_FOR}_cooccurence/{GENERATE_FOR}_(carts)vs(carts)_cooccurences_v10_*.pqt\"))\n",
    "co_cart_v_cart = pd.concat([pd.read_parquet(f) for f in co_cart_v_cart], ignore_index=True)\n",
    "\n",
    "co_click_v_order = sorted(glob.glob(f\"../raw_data/{GENERATE_FOR}_cooccurence/{GENERATE_FOR}_(clicks)vs(orders)_cooccurences_v10_*.pqt\"))\n",
    "co_click_v_order = pd.concat([pd.read_parquet(f) for f in co_click_v_order], ignore_index=True)\n",
    "\n",
    "co_cart_v_order = sorted(glob.glob(f\"../raw_data/{GENERATE_FOR}_cooccurence/{GENERATE_FOR}_(carts)vs(orders)_cooccurences_v10_*.pqt\"))\n",
    "co_cart_v_order = pd.concat([pd.read_parquet(f) for f in co_cart_v_order], ignore_index=True)\n",
    "\n",
    "co_click_v_cart = sorted(glob.glob(f\"../raw_data/{GENERATE_FOR}_cooccurence/{GENERATE_FOR}_(clicks)vs(carts)_cooccurences_v10_*.pqt\"))\n",
    "co_click_v_cart = pd.concat([pd.read_parquet(f) for f in co_click_v_cart], ignore_index=True)\n",
    "\n",
    "co_order_v_cart = sorted(glob.glob(f\"../raw_data/{GENERATE_FOR}_cooccurence/{GENERATE_FOR}_(orders)vs(carts)_cooccurences_v10_*.pqt\"))\n",
    "co_order_v_cart = pd.concat([pd.read_parquet(f) for f in co_order_v_cart], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f098ab99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2300870/2583299799.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  co_df_w_probs = co_df.\\\n",
      "/tmp/ipykernel_2300870/2583299799.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  co_df_w_probs = co_df.\\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aid_x</th>\n",
       "      <th>aid_y</th>\n",
       "      <th>PPMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22107</td>\n",
       "      <td>10.778619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16151</td>\n",
       "      <td>22107</td>\n",
       "      <td>5.461979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56067</td>\n",
       "      <td>22107</td>\n",
       "      <td>13.814243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115315</td>\n",
       "      <td>22107</td>\n",
       "      <td>12.136171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>144135</td>\n",
       "      <td>22107</td>\n",
       "      <td>7.517786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    aid_x  aid_y       PPMI\n",
       "0       3  22107  10.778619\n",
       "1   16151  22107   5.461979\n",
       "2   56067  22107  13.814243\n",
       "3  115315  22107  12.136171\n",
       "4  144135  22107   7.517786"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2300870/2583299799.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  co_df_w_probs = co_df.\\\n",
      "/tmp/ipykernel_2300870/2583299799.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  co_df_w_probs = co_df.\\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aid_x</th>\n",
       "      <th>aid_y</th>\n",
       "      <th>PPMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>279811</td>\n",
       "      <td>17.684593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17569</td>\n",
       "      <td>279811</td>\n",
       "      <td>10.765730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29292</td>\n",
       "      <td>279811</td>\n",
       "      <td>8.670573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75643</td>\n",
       "      <td>279811</td>\n",
       "      <td>11.640199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>124588</td>\n",
       "      <td>279811</td>\n",
       "      <td>9.808076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    aid_x   aid_y       PPMI\n",
       "0       1  279811  17.684593\n",
       "1   17569  279811  10.765730\n",
       "2   29292  279811   8.670573\n",
       "3   75643  279811  11.640199\n",
       "4  124588  279811   9.808076"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2300870/2583299799.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  co_df_w_probs = co_df.\\\n",
      "/tmp/ipykernel_2300870/2583299799.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  co_df_w_probs = co_df.\\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aid_x</th>\n",
       "      <th>aid_y</th>\n",
       "      <th>PPMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>643097</td>\n",
       "      <td>16.777676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3979</td>\n",
       "      <td>643097</td>\n",
       "      <td>7.302829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40106</td>\n",
       "      <td>643097</td>\n",
       "      <td>15.162966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42386</td>\n",
       "      <td>643097</td>\n",
       "      <td>9.485354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52415</td>\n",
       "      <td>643097</td>\n",
       "      <td>8.920472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   aid_x   aid_y       PPMI\n",
       "0      0  643097  16.777676\n",
       "1   3979  643097   7.302829\n",
       "2  40106  643097  15.162966\n",
       "3  42386  643097   9.485354\n",
       "4  52415  643097   8.920472"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2300870/2583299799.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  co_df_w_probs = co_df.\\\n",
      "/tmp/ipykernel_2300870/2583299799.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  co_df_w_probs = co_df.\\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aid_x</th>\n",
       "      <th>aid_y</th>\n",
       "      <th>PPMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1771163</td>\n",
       "      <td>7.196210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1414</td>\n",
       "      <td>1771163</td>\n",
       "      <td>2.871470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4051</td>\n",
       "      <td>1771163</td>\n",
       "      <td>7.518138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5890</td>\n",
       "      <td>1771163</td>\n",
       "      <td>6.483373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6517</td>\n",
       "      <td>1771163</td>\n",
       "      <td>2.702013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   aid_x    aid_y      PPMI\n",
       "0      3  1771163  7.196210\n",
       "1   1414  1771163  2.871470\n",
       "2   4051  1771163  7.518138\n",
       "3   5890  1771163  6.483373\n",
       "4   6517  1771163  2.702013"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2300870/2583299799.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  co_df_w_probs = co_df.\\\n",
      "/tmp/ipykernel_2300870/2583299799.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  co_df_w_probs = co_df.\\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aid_x</th>\n",
       "      <th>aid_y</th>\n",
       "      <th>PPMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>532042</td>\n",
       "      <td>13.543125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1836</td>\n",
       "      <td>532042</td>\n",
       "      <td>9.498731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3186</td>\n",
       "      <td>532042</td>\n",
       "      <td>8.963181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6594</td>\n",
       "      <td>532042</td>\n",
       "      <td>7.899269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7483</td>\n",
       "      <td>532042</td>\n",
       "      <td>5.843842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   aid_x   aid_y       PPMI\n",
       "0      0  532042  13.543125\n",
       "1   1836  532042   9.498731\n",
       "2   3186  532042   8.963181\n",
       "3   6594  532042   7.899269\n",
       "4   7483  532042   5.843842"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2300870/2583299799.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  co_df_w_probs = co_df.\\\n",
      "/tmp/ipykernel_2300870/2583299799.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  co_df_w_probs = co_df.\\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aid_x</th>\n",
       "      <th>aid_y</th>\n",
       "      <th>PPMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>597886</td>\n",
       "      <td>7.699745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11459</td>\n",
       "      <td>597886</td>\n",
       "      <td>6.034929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15916</td>\n",
       "      <td>597886</td>\n",
       "      <td>7.249942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20945</td>\n",
       "      <td>597886</td>\n",
       "      <td>8.472334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27425</td>\n",
       "      <td>597886</td>\n",
       "      <td>5.199316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   aid_x   aid_y      PPMI\n",
       "0      3  597886  7.699745\n",
       "1  11459  597886  6.034929\n",
       "2  15916  597886  7.249942\n",
       "3  20945  597886  8.472334\n",
       "4  27425  597886  5.199316"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_PPMI_features(co_df,\n",
    "                           count_df,\n",
    "                           aidx_type=\"order\",\n",
    "                           aidy_type=\"order\"):\n",
    "    co_df_w_probs = co_df.\\\n",
    "        merge(count_df[[\"aid\", f\"{aidx_type}_prob\"]], left_on=\"aid_x\", right_on=\"aid\").drop(\"aid\", 1).\\\n",
    "                rename(columns={f\"{aidx_type}_prob\": \"aid_x_prob\"}).\\\n",
    "        merge(count_df[[\"aid\", f\"{aidy_type}_prob\"]], left_on=\"aid_y\", right_on=\"aid\").drop(\"aid\", 1).\\\n",
    "                rename(columns={f\"{aidy_type}_prob\": \"aid_y_prob\"})\n",
    "\n",
    "    co_df_w_probs[\"pair_prob\"] = (co_df_w_probs[\"wgt\"] / co_df_w_probs[\"wgt\"].sum())\n",
    "    \n",
    "    co_df_w_probs[\"PPMI\"] =\\\n",
    "    np.maximum(np.log2(co_df_w_probs[\"pair_prob\"] /\\\n",
    "                       (co_df_w_probs[\"aid_x_prob\"] * co_df_w_probs[\"aid_y_prob\"])), 0)\n",
    "    \n",
    "    return co_df_w_probs[[\"aid_x\", \"aid_y\", \"PPMI\"]]\n",
    "\n",
    "aid_count_df = pd.read_parquet(f'./all_features/{GENERATE_FOR}_aid_occurences.pqt')\n",
    "\n",
    "ppmi_target_combs = [\n",
    "    [co_order_v_order, \"order\", \"order\"],\n",
    "    [co_cart_v_cart, \"cart\", \"cart\"],\n",
    "    [co_click_v_order, \"click\", \"order\"],\n",
    "    [co_cart_v_order, \"cart\", \"order\"],\n",
    "    [co_click_v_cart, \"click\", \"cart\"],\n",
    "    [co_order_v_cart, \"order\", \"cart\"],\n",
    "]\n",
    "\n",
    "for ppmi_target_comb in ppmi_target_combs:\n",
    "    ppmi_df = generate_PPMI_features(co_df=ppmi_target_comb[0],\n",
    "                                     count_df=aid_count_df,\n",
    "                                     aidx_type=ppmi_target_comb[1],\n",
    "                                     aidy_type=ppmi_target_comb[2])\n",
    "    \n",
    "    ppmi_df.to_parquet(f'./all_features/{GENERATE_FOR}_ppmi_{ppmi_target_comb[1]}_{ppmi_target_comb[2]}.pqt')\n",
    "    display(ppmi_df.head())\n",
    "    del ppmi_df; gc.collect()\n",
    "    \n",
    "del co_order_v_order, co_cart_v_cart, co_click_v_order, co_cart_v_order, co_click_v_cart, co_order_v_cart; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dff2ff44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b39e64e5631745748db49862c42edc8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11b865967f9461b8868232e6cbfe75f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44306052ad4d41c08d771ebe4ab7f7c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba51f1d88b8743eca30886ffac408070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score_df_tuples_w_names = [[pl.read_parquet(f\"./all_features/{GENERATE_FOR}_ppmi_order_cart.pqt\"),\n",
    "                            \"order_vs_cart\", [2]],\n",
    "                            [pl.read_parquet(f\"./all_features/{GENERATE_FOR}_ppmi_click_cart.pqt\"),\n",
    "                            \"click_vs_cart\", [0]],\n",
    "                           [pl.read_parquet(f\"./all_features/{GENERATE_FOR}_ppmi_cart_cart.pqt\"),\n",
    "                            \"cart_vs_cart\", [1]],\n",
    "                           [pl.read_parquet(f\"./all_features/{GENERATE_FOR}_ppmi_click_order.pqt\"),\n",
    "                            \"click_vs_order\", [0]],\n",
    "                           [pl.read_parquet(f\"./all_features/{GENERATE_FOR}_ppmi_order_order.pqt\"),\n",
    "                            \"order_vs_order\", [2]],\n",
    "                           [pl.read_parquet(f\"./all_features/{GENERATE_FOR}_ppmi_cart_order.pqt\"),\n",
    "                            \"cart_vs_order\", [1]]\n",
    "                          ]\n",
    "\n",
    "generate_candidate_history_pair_score_features(input_val_df_path=val_path,\n",
    "                                               score_df_tuples_w_names=score_df_tuples_w_names,\n",
    "                                               score_col=\"PPMI\",\n",
    "                                               scoring_name=\"ppmi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7826c4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a7933901f4045f888beca50418e03c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c12c783982fa4373be0aa91762e8e1fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ec5cdc945c49f5a4140a2e41cd1d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8bbbd7446f549f79601389992f41df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score_df_tuples_w_names = [[pl.read_parquet(f\"./all_features/{GENERATE_FOR}_ppmi_order_cart.pqt\"),\n",
    "                            \"order_vs_cart\", None],\n",
    "                            [pl.read_parquet(f\"./all_features/{GENERATE_FOR}_ppmi_click_cart.pqt\"),\n",
    "                            \"click_vs_cart\", None],\n",
    "                           [pl.read_parquet(f\"./all_features/{GENERATE_FOR}_ppmi_cart_cart.pqt\"),\n",
    "                            \"cart_vs_cart\", None],\n",
    "                           [pl.read_parquet(f\"./all_features/{GENERATE_FOR}_ppmi_click_order.pqt\"),\n",
    "                            \"click_vs_order\", None],\n",
    "                           [pl.read_parquet(f\"./all_features/{GENERATE_FOR}_ppmi_order_order.pqt\"),\n",
    "                            \"order_vs_order\", None],\n",
    "                           [pl.read_parquet(f\"./all_features/{GENERATE_FOR}_ppmi_cart_order.pqt\"),\n",
    "                            \"cart_vs_order\", None]\n",
    "                          ]\n",
    "\n",
    "generate_candidate_history_pair_score_features(input_val_df_path=val_path,\n",
    "                                               score_df_tuples_w_names=score_df_tuples_w_names,\n",
    "                                               score_col=\"PPMI\",\n",
    "                                               scoring_name=\"ppmi_all_history\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a80ce4",
   "metadata": {},
   "source": [
    "### Common Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d12a0c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datetime_aggregator(input_df,\n",
    "                        group_cols=[],\n",
    "                        wanted_cols=[]):\n",
    "    return_df = input_df.groupby(group_cols).agg(\n",
    "        {'hour':['mean', 'std'],\n",
    "         'dayofweek':['mean', 'std'],\n",
    "         'is_weekend':['mean']\n",
    "        })\n",
    "    return_df.columns = ['_'.join(group_cols) + '_' +  '_'.join(col) for col in return_df.columns]\n",
    "    return return_df\n",
    "\n",
    "def type_distribution_aggregator(input_df, \n",
    "                                 group_cols=[]):\n",
    "    return_df = input_df.groupby(group_cols)['type'].value_counts(normalize=True)\n",
    "    return_df = return_df.unstack('type')\n",
    "    return_df.columns = ['_'.join(group_cols) + '_type' + str(col) + \"_mean\" for col in return_df.columns]\n",
    "    return return_df\n",
    "\n",
    "def type_based_aggregator(input_df,\n",
    "                          group_cols=[],\n",
    "                          wanted_cols=[],\n",
    "                          aggregators=[]):\n",
    "    type_dfs = []\n",
    "    for type_id in range(3):\n",
    "        for aggregator in aggregators:\n",
    "            aggregator_df = aggregator(input_df[input_df.type==type_id].reset_index(drop=True),\n",
    "                                       group_cols=group_cols,\n",
    "                                       wanted_cols=wanted_cols)\n",
    "            aggregator_df.columns = [\"type\" + str(type_id) + \"_\" + col for col in aggregator_df.columns]\n",
    "        type_dfs.append(aggregator_df)\n",
    "        \n",
    "    return pd.concat(type_dfs, axis=1)\n",
    "\n",
    "def existence_amount_aggregator(input_df,\n",
    "                                 group_cols=[],\n",
    "                                wanted_cols=[],\n",
    "                                return_counts=False):\n",
    "    \n",
    "    return_df = input_df.groupby(group_cols).agg({col:[\"count\"] for col in wanted_cols})\n",
    "    return_df.columns = ['_'.join(group_cols) + '_' +  '_'.join(col) for col in return_df.columns]\n",
    "        \n",
    "    return_df['_'.join(group_cols) + '_cnt_pct_rank'] =\\\n",
    "            return_df[return_df.columns[0]].rank(pct=True).astype(np.float32)\n",
    "    \n",
    "    count_cols = list(return_df.columns[:1])\n",
    "    \n",
    "    for count_col in count_cols:  \n",
    "        return_df[count_col.replace(\"count\", \"existed\")] = (return_df[count_col]>0).astype(int)\n",
    "        return_df[count_col.replace(\"count\", \"existed_multiple\")] = (return_df[count_col]>1).astype(int)\n",
    "        if return_counts:\n",
    "            return_df[count_col.replace(\"count\", \"existed_times\")] = (return_df[count_col]).astype(int)\n",
    "    \n",
    "    return_df = return_df[[col for col in return_df.columns if (\"count\" not in col)]]\n",
    "    \n",
    "    return return_df\n",
    "\n",
    "def nunique_aggregator(input_df,\n",
    "                       group_cols=[],\n",
    "                       wanted_cols=[]):\n",
    "    \n",
    "    return_df = input_df.groupby(group_cols).agg({col:[\"nunique\"] for col in wanted_cols})\n",
    "    return_df.columns = ['_'.join(group_cols) + '_' +  '_'.join(col) for col in return_df.columns]\n",
    "    \n",
    "    return_df['_'.join(group_cols) + '_nunq_pct_rank'] =\\\n",
    "            return_df[return_df.columns[0]].rank(pct=True).astype(np.float32)\n",
    "        \n",
    "\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966bdf62",
   "metadata": {},
   "source": [
    "### Item Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "436a2a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_interacted_by_sessions_perc(input_df,\n",
    "              group_cols=[\"aid\"],\n",
    "              wanted_cols=[]\n",
    "             ):\n",
    "    return_feature_list = []\n",
    "    copy_df = input_df.copy()\n",
    "    session_count = copy_df.session.nunique()\n",
    "    \n",
    "    return_df = 2\n",
    "    \n",
    "    for type_str in tqdm(type_labels.keys()):\n",
    "        colname = f\"session_toitem_{type_str}_perc\"\n",
    "        type_df = copy_df[copy_df.type==type_labels[type_str]].groupby([\"aid\", \"session\"])[\"ts\"].count()    \n",
    "        type_df = type_df.reset_index().groupby(\"aid\")[\"session\"].count().rename(colname).to_frame() / session_count\n",
    "        if isinstance(return_df, int):\n",
    "            return_df = type_df.copy()\n",
    "        else:\n",
    "            return_df = return_df.merge(type_df, how=\"outer\", on=\"aid\")\n",
    "            \n",
    "    return return_df.fillna(0.)\n",
    "\n",
    "\n",
    "def item_lastweek_features(input_df,\n",
    "              group_cols=[\"aid\"],\n",
    "              wanted_cols=[]\n",
    "             ):\n",
    "    \n",
    "    input_df[\"ts\"] = pd.to_datetime(input_df[\"ts\"], unit=\"s\")\n",
    "    input_df[\"week\"] = input_df[\"ts\"].dt.week\n",
    "    \n",
    "    all_group_ids = pd.MultiIndex.from_product([input_df.aid.unique(),\n",
    "                                                input_df.week.unique(),\n",
    "                                                [0,1,2]],\n",
    "                                               names=['aid', 'week', 'type'])\n",
    "\n",
    "    return_dfs = []\n",
    "    \n",
    "    for aggfunc in [\"count\", \"nunique\"]:\n",
    "        grouped = input_df.groupby(['aid', 'week', 'type'])[\"session\"].agg(aggfunc).rename(aggfunc)\n",
    "        grouped = grouped.reindex(all_group_ids, fill_value=0).reset_index()\n",
    "\n",
    "        aid_lastweek_occ_ratio = (grouped.groupby([\"aid\", \"type\"])[aggfunc].last() /\\\n",
    "                                grouped.groupby([\"aid\", \"type\"])[aggfunc].sum()).fillna(0.).unstack('type')\n",
    "        aid_lastweek_occ_ratio.columns = [ f\"type_{col}_lastweek_{aggfunc}_occ_ratio\" for col in aid_lastweek_occ_ratio]        \n",
    "        return_dfs.append(aid_lastweek_occ_ratio)\n",
    "        \n",
    "        aid_lastweek_occ_amount = grouped.groupby([\"aid\", \"type\"])[aggfunc].last().fillna(0.).unstack('type')\n",
    "        aid_lastweek_occ_amount.columns = [ f\"type_{col}_lastweek_{aggfunc}_occ_amount\" for col in aid_lastweek_occ_amount]        \n",
    "        return_dfs.append(aid_lastweek_occ_amount)\n",
    "        \n",
    "        grouped[\"pct_change\"] = grouped.groupby([\"aid\", \"type\"])[aggfunc].pct_change()\n",
    "\n",
    "        aid_lastweek_pct_change = grouped.groupby([\"aid\", \"type\"])[\"pct_change\"].last().fillna(-999.).\\\n",
    "                    replace([np.inf, -np.inf], -999.).unstack('type')\n",
    "        aid_lastweek_pct_change.columns = [ f\"type_{col}_lastweek_{aggfunc}_pct_change\" for col in aid_lastweek_pct_change]\n",
    "        return_dfs.append(aid_lastweek_pct_change)\n",
    "        \n",
    "    return pd.concat(return_dfs, axis=1)\n",
    "\n",
    "def item_recurrent_signal(input_df,\n",
    "                          group_cols=[],\n",
    "                          wanted_cols=[]):\n",
    "    \n",
    "    item_recurrent_signal_df = input_df.groupby(['aid','session'])[\"ts\"].nunique()\\\n",
    "            .rename(\"recurrent_session_acts_per_item\").reset_index()\n",
    "    \n",
    "    item_recurrent_signal_df = item_recurrent_signal_df.groupby('aid').agg({\n",
    "        'recurrent_session_acts_per_item': ['mean'],\n",
    "    })\n",
    "    item_recurrent_signal_df.columns = ['aid_' +  '_'.join(col) for col in item_recurrent_signal_df.columns]\n",
    "\n",
    "    return item_recurrent_signal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b2f2503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb71c189e174681a2d691faa4e3ae58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2807567/4022283028.py:29: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  input_df[\"week\"] = input_df[\"ts\"].dt.week\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item features are created!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features = pd.concat([\n",
    "    existence_amount_aggregator(item_df,\n",
    "                                group_cols=[\"aid\"],\n",
    "                                wanted_cols=[\"session\", \"aid\"]),\n",
    "    nunique_aggregator(item_df,\n",
    "                       group_cols=[\"aid\"],\n",
    "                       wanted_cols=[\"session\"]),\n",
    "    datetime_aggregator(item_df,\n",
    "                        group_cols=[\"aid\"]),\n",
    "    type_distribution_aggregator(item_df,\n",
    "                                 group_cols=[\"aid\"]),\n",
    "    item_interacted_by_sessions_perc(item_df),\n",
    "    item_lastweek_features(item_df),\n",
    "    item_recurrent_signal(item_df),\n",
    "    type_based_aggregator(item_df,\n",
    "                          group_cols=[\"aid\"],\n",
    "                          wanted_cols=[\"aid\", \"session\"],\n",
    "                          aggregators=[datetime_aggregator,\n",
    "                                       nunique_aggregator,\n",
    "                                       existence_amount_aggregator,\n",
    "                                      item_recurrent_signal])\n",
    "], axis=1)\n",
    "\n",
    "item_features = reduce_memory(item_features)\n",
    "\n",
    "item_features.to_parquet(f'./all_features/{GENERATE_FOR}_item_features.pqt')\n",
    "\n",
    "print(\"Item features are created!\")\n",
    "\n",
    "del item_features; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b95c571",
   "metadata": {},
   "source": [
    "### User Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0b85dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def session_len(input_df,\n",
    "                group_cols=[\"session\"],\n",
    "                wanted_cols=[],\n",
    "                return_min_max=False\n",
    "               ):\n",
    "    return_df = input_df[group_cols + [\"ts\"]].copy()\n",
    "    return_df = return_df.groupby(group_cols).agg({\"ts\":[\"min\", \"max\"]})\n",
    "    return_df.columns = [\"session_start\", \"session_end\"]\n",
    "    return_df[\"session_len\"] = return_df[\"session_end\"] - return_df[\"session_start\"]\n",
    "    \n",
    "    if return_min_max:\n",
    "        return return_df\n",
    "    else:\n",
    "        return return_df[[\"session_len\"]]\n",
    "    \n",
    "def partial_session_features(input_df,\n",
    "                        group_cols=[\"session\"],\n",
    "                        wanted_cols=[]\n",
    "           ):\n",
    "    \n",
    "    return_feature_list = []\n",
    "    \n",
    "    return_df = input_df.copy()\n",
    "    return_df[\"ts_diff_gt_thr\"] = (return_df.groupby(\"session\")[\"ts\"].diff() > 60*60*6).astype(int)\n",
    "    return_df[\"partial_session_id\"] = return_df.groupby(\"session\")[\"ts_diff_gt_thr\"].cumsum()\n",
    "\n",
    "    max_partial_sessions_per_session = return_df.groupby(\"session\")[\"partial_session_id\"].\\\n",
    "                max().rename(\"max_partial_session_id\")\n",
    "    return_feature_list.append(\"max_partial_session_id\")\n",
    "    \n",
    "    return_df = return_df.merge(max_partial_sessions_per_session, how=\"left\", on=\"session\")\n",
    "\n",
    "    #########\n",
    "    \n",
    "    mean_nunq_items = return_df.groupby([\"session\", \"partial_session_id\"])[\"aid\"].nunique().\\\n",
    "        reset_index().groupby(\"session\")[\"aid\"].mean().rename(\"partial_mean_nunique_aid\")\n",
    "    return_df = return_df.merge(mean_nunq_items, how=\"left\", on=\"session\")\n",
    "    return_feature_list.append(\"partial_mean_nunique_aid\")\n",
    "\n",
    "    #########\n",
    "    \n",
    "    mean_items = return_df.groupby([\"session\", \"partial_session_id\"])[\"aid\"].count().\\\n",
    "        reset_index().groupby(\"session\")[\"aid\"].mean().rename(\"partial_mean_count_aid\")\n",
    "    return_df = return_df.merge(mean_items, how=\"left\", on=\"session\")\n",
    "    return_feature_list.append(\"partial_mean_count_aid\")\n",
    "\n",
    "    #########\n",
    "    \n",
    "    for type_str in type_labels.keys():\n",
    "        mean_type_colname = f\"partial_mean_{type_str}\"\n",
    "        mean_type = return_df[return_df.type==type_labels[type_str]].groupby([\"session\", \"partial_session_id\"])[\"ts\"].count().\\\n",
    "            reset_index().groupby(\"session\")[\"ts\"].mean().rename(mean_type_colname)\n",
    "        return_df = return_df.merge(mean_type, how=\"left\", on=\"session\").fillna(0)\n",
    "        return_feature_list.append(mean_type_colname)    \n",
    "\n",
    "        #########\n",
    "        \n",
    "        mean_type_colname = f\"partial_mean_tsdiff_{type_str}\"\n",
    "        return_df.loc[return_df.type==type_labels[type_str], \"ts_diff\"] =\\\n",
    "            return_df[return_df.type==type_labels[type_str]].groupby([\"session\", \"partial_session_id\"])[\"ts\"].\\\n",
    "                    diff().rename(\"ts_diff\")\n",
    "        \n",
    "        ts_meandiff = return_df[return_df.type==type_labels[type_str]].groupby(\"session\")[\"ts_diff\"].mean().rename(mean_type_colname)\n",
    "        return_df = return_df.merge(ts_meandiff, how=\"left\", on=\"session\").fillna(-999)\n",
    "        return_feature_list.append(mean_type_colname)    \n",
    "        \n",
    "        #########\n",
    "        \n",
    "    return return_df[[\"session\"] + return_feature_list].groupby(\"session\").first()\n",
    "\n",
    "def order_size_stats(input_df,\n",
    "                        group_cols=[\"session\"],\n",
    "                        wanted_cols=[]\n",
    "           ):\n",
    "    return_df = input_df[input_df.type==2].reset_index().copy()\n",
    "    \n",
    "    order_size_stat_df = return_df.groupby([\"session\", \"ts\"]).agg({\"aid\":[\"nunique\"]})\n",
    "    order_size_stat_df.columns = [\"aid_in_orders_nunique\"]\n",
    "    order_size_stat_df = order_size_stat_df.reset_index().groupby(\"session\").agg({\n",
    "        \"aid_in_orders_nunique\": [\"min\", \"max\", \"mean\"]\n",
    "    })\n",
    "    order_size_stat_df.columns = ['_'.join(group_cols) + '_' +  '_'.join(col) for col in order_size_stat_df.columns]\n",
    "    return order_size_stat_df\n",
    "\n",
    "def user_action_conversion_ratios(input_df,\n",
    "                                  group_cols=[\"session\"],\n",
    "                                  wanted_cols=[]\n",
    "                                 ):\n",
    "    return_df = input_df.copy()\n",
    "    \n",
    "    for i in range(3):\n",
    "        return_df.loc[return_df.type==i, f\"type_{i}\"] = 1\n",
    "    return_df.fillna(0., inplace=True)\n",
    "    \n",
    "    return_df = return_df.groupby([\"session\", \"aid\"]).agg({\"type_0\": \"max\",\n",
    "                                                 \"type_1\": \"max\",\n",
    "                                                 \"type_2\": \"max\"}).reset_index()\n",
    "    return_df[\"session_click_cart_relation\"] = ((return_df[\"type_0\"] == 1.) & return_df[\"type_1\"] == 1.).astype(int)\n",
    "    return_df[\"session_click_order_relation\"] = ((return_df[\"type_0\"] == 1.) & return_df[\"type_2\"] == 1.).astype(int)\n",
    "    return_df[\"session_cart_order_relation\"] = ((return_df[\"type_1\"] == 1.) & return_df[\"type_2\"] == 1.).astype(int)\n",
    "    \n",
    "    return_df = return_df.groupby([\"session\"]).agg({\n",
    "        \"session_click_cart_relation\":\"mean\",\n",
    "        \"session_click_order_relation\":\"mean\",\n",
    "        \"session_cart_order_relation\":\"mean\",\n",
    "    })\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "397c408a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User features are created!\n"
     ]
    }
   ],
   "source": [
    "user_features = pd.concat([\n",
    "    existence_amount_aggregator(user_df,\n",
    "                                group_cols=[\"session\"],\n",
    "                                wanted_cols=[\"session\", \"aid\"]),\n",
    "    session_len(user_df),\n",
    "    nunique_aggregator(user_df,\n",
    "                       group_cols=[\"session\"],\n",
    "                       wanted_cols=[\"aid\"]),\n",
    "    datetime_aggregator(user_df,\n",
    "                        group_cols=[\"session\"]),\n",
    "    type_distribution_aggregator(user_df,\n",
    "                                 group_cols=[\"session\"]),\n",
    "    partial_session_features(user_df),\n",
    "    order_size_stats(user_df),\n",
    "    user_action_conversion_ratios(user_df),\n",
    "    type_based_aggregator(user_df,\n",
    "                          group_cols=[\"session\"],\n",
    "                          wanted_cols=[\"aid\", \"session\"],\n",
    "                          aggregators=[datetime_aggregator,\n",
    "                                       session_len,\n",
    "                                       nunique_aggregator,\n",
    "                                       existence_amount_aggregator])\n",
    "], axis=1)\n",
    "\n",
    "user_features = reduce_memory(user_features)\n",
    "\n",
    "user_features.to_parquet(f'./all_features/{GENERATE_FOR}_user_features.pqt')\n",
    "\n",
    "print(\"User features are created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06276e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "del user_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62810d2d",
   "metadata": {},
   "source": [
    "### User-Item Interaction Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68a2d28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_last_aid_of_the_session(input_df,\n",
    "                               group_cols=[\"session\", \"aid\"],\n",
    "                               wanted_cols=[]\n",
    "                              ):\n",
    "    \n",
    "    return_df = input_df[group_cols].copy()\n",
    "    return_df[\"is_aid_interacted_last\"] = 0\n",
    "    return_df.loc[return_df.session.shift(-1) != return_df.session, \"is_aid_interacted_last\"] = 1\n",
    "    return_df = return_df.groupby(group_cols).agg({\"is_aid_interacted_last\":[\"max\"]})\n",
    "    return_df.columns = [\"is_aid_interacted_last_in_session\"]\n",
    "    return return_df\n",
    "\n",
    "def aid_session_ts_offsets(input_df,\n",
    "                group_cols=[\"session\", \"aid\"],\n",
    "                wanted_cols=[]):\n",
    "    session_lens = session_len(input_df,\n",
    "                               return_min_max=True).reset_index()\n",
    "    return_df = input_df[group_cols + [\"ts\"]].copy()\n",
    "    return_df = return_df.groupby(group_cols).agg({\"ts\":[\"last\"]})\n",
    "    return_df.columns = [\"session_aid_last_ts\"]\n",
    "    return_df.reset_index(inplace=True)\n",
    "    return_df = return_df.merge(session_lens, how=\"left\", on=\"session\")\n",
    "    return_df[\"aid_ts_session_end_offset\"] = return_df[\"session_end\"] - return_df[\"session_aid_last_ts\"]\n",
    "    return_df[\"aid_ts_session_start_offset\"] = return_df[\"session_aid_last_ts\"] - return_df[\"session_start\"]\n",
    "\n",
    "    return_df = return_df[group_cols + [\"aid_ts_session_end_offset\", \"aid_ts_session_start_offset\"]].set_index(group_cols)\n",
    "    return return_df\n",
    "\n",
    "def reverse_order_of_aid_for_session(input_df,\n",
    "                               group_cols=[\"session\", \"aid\"],\n",
    "                               wanted_cols=[]\n",
    "                              ):\n",
    "    \n",
    "    return_df = input_df[group_cols].copy()\n",
    "    \n",
    "    return_df.loc[:, \"session_action_order\"] = return_df.groupby(\"session\")[\"aid\"].cumcount()\n",
    "\n",
    "    session_aid_counts = return_df.groupby(\"session\")[\"aid\"].count()\\\n",
    "                        .rename(\"session_action_count\").reset_index()\n",
    "    return_df = return_df.merge(session_aid_counts, how=\"left\", on=\"session\")\n",
    "    return_df[\"session_action_order\"] = return_df[\"session_action_count\"] - return_df[\"session_action_order\"]\n",
    "    \n",
    "    return_df = return_df.groupby(group_cols)[\"session_action_order\"].min().rename(\"session_action_last_order\").to_frame()\n",
    "    \n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ede33468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-Item Interaction features are created!\n"
     ]
    }
   ],
   "source": [
    "user_item_int_features = pd.concat([\n",
    "    existence_amount_aggregator(user_item_int_df,\n",
    "                                group_cols=[\"session\", \"aid\"],\n",
    "                                wanted_cols=[\"aid\"],\n",
    "                                return_counts=True),\n",
    "    reverse_order_of_aid_for_session(user_item_int_df),\n",
    "    aid_session_ts_offsets(user_item_int_df),\n",
    "#     nunique_aggregator(user_df,\n",
    "#                        group_cols=[\"session\"],\n",
    "#                        wanted_cols=[\"aid\"]),\n",
    "    datetime_aggregator(user_item_int_df,\n",
    "                        group_cols=['session', 'aid']),\n",
    "    type_distribution_aggregator(user_item_int_df,\n",
    "                                 group_cols=['session', 'aid']),\n",
    "    type_based_aggregator(user_item_int_df,\n",
    "                          group_cols=['session', 'aid'],\n",
    "                          wanted_cols=[\"aid\"],\n",
    "                          aggregators=[datetime_aggregator,\n",
    "                                       reverse_order_of_aid_for_session,\n",
    "                                       aid_session_ts_offsets,\n",
    "#                                        nunique_aggregator,\n",
    "                                       existence_amount_aggregator])\n",
    "], axis=1)\n",
    "\n",
    "user_item_int_features = reduce_memory(user_item_int_features)\n",
    "\n",
    "user_item_int_features.to_parquet(f'./all_features/{GENERATE_FOR}_user_item_int_features.pqt')\n",
    "\n",
    "print(\"User-Item Interaction features are created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a360283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del user_item_int_features\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a850637",
   "metadata": {},
   "outputs": [],
   "source": [
    "del item_df, train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d02a64d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory: ../raw_data/kaggle_ppmi_features/ppmi_features_clicks_100candidates.pqt",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ppmi_feature_df \u001b[38;5;241m=\u001b[39m \u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../raw_data/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mGENERATE_FOR\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_ppmi_features/ppmi_features_clicks_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mCANDIDATE_COUNT\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43mcandidates.pqt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.8/site-packages/polars/utils.py:337\u001b[0m, in \u001b[0;36mdeprecated_alias.<locals>.deco.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    336\u001b[0m     _rename_kwargs(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, kwargs, aliases)\n\u001b[0;32m--> 337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.8/site-packages/polars/io.py:687\u001b[0m, in \u001b[0;36mscan_parquet\u001b[0;34m(file, n_rows, cache, parallel, rechunk, row_count_name, row_count_offset, storage_options, low_memory)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(file, (\u001b[38;5;28mstr\u001b[39m, Path)):\n\u001b[1;32m    685\u001b[0m     file \u001b[38;5;241m=\u001b[39m format_path(file)\n\u001b[0;32m--> 687\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLazyFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_scan_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrechunk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrechunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrow_count_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow_count_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrow_count_offset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow_count_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.8/site-packages/polars/internals/lazyframe/frame.py:198\u001b[0m, in \u001b[0;36mLazyFrame._scan_parquet\u001b[0;34m(cls, file, n_rows, cache, parallel, rechunk, row_count_name, row_count_offset, storage_options, low_memory)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# try fsspec scanner\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pli\u001b[38;5;241m.\u001b[39m_is_local_file(file):\n\u001b[0;32m--> 198\u001b[0m     scan \u001b[38;5;241m=\u001b[39m \u001b[43mpli\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_scan_parquet_fsspec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_rows:\n\u001b[1;32m    200\u001b[0m         scan \u001b[38;5;241m=\u001b[39m scan\u001b[38;5;241m.\u001b[39mhead(n_rows)\n",
      "File \u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.8/site-packages/polars/internals/anonymous_scan.py:148\u001b[0m, in \u001b[0;36m_scan_parquet_fsspec\u001b[0;34m(file, storage_options)\u001b[0m\n\u001b[1;32m    146\u001b[0m storage_options \u001b[38;5;241m=\u001b[39m storage_options \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pli\u001b[38;5;241m.\u001b[39m_prepare_file_arg(file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mstorage_options) \u001b[38;5;28;01mas\u001b[39;00m data:\n\u001b[0;32m--> 148\u001b[0m     schema \u001b[38;5;241m=\u001b[39m \u001b[43mpli\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pli\u001b[38;5;241m.\u001b[39mLazyFrame\u001b[38;5;241m.\u001b[39m_scan_python_function(schema, func_serialized)\n",
      "File \u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.8/site-packages/polars/internals/io.py:178\u001b[0m, in \u001b[0;36mread_parquet_schema\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(file, (\u001b[38;5;28mstr\u001b[39m, Path)):\n\u001b[1;32m    176\u001b[0m     file \u001b[38;5;241m=\u001b[39m format_path(file)\n\u001b[0;32m--> 178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parquet_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory: ../raw_data/kaggle_ppmi_features/ppmi_features_clicks_100candidates.pqt"
     ]
    }
   ],
   "source": [
    "ppmi_feature_df = pl.scan_parquet(f'../raw_data/{GENERATE_FOR}_ppmi_features/ppmi_features_clicks_{CANDIDATE_COUNT}candidates.pqt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03248e26",
   "metadata": {},
   "source": [
    "## Merging Features w/ Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36ce29ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading item features...\n",
      "Reading user features...\n",
      "Reading user-item interaction features...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ef418788c75458d80ed7f6f505f77e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d3e9f95e774e55888cf66c78857d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36abf78385634fe6b79a9a94c2382ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bed8375d1724feeb67d20bd9dd20817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Reading item features...\")\n",
    "item_features = pl.scan_parquet(f'./all_features/{GENERATE_FOR}_item_features.pqt')\n",
    "print(\"Reading user features...\")\n",
    "user_features = pl.scan_parquet(f'./all_features/{GENERATE_FOR}_user_features.pqt')\n",
    "print(\"Reading user-item interaction features...\")\n",
    "user_item_int_features = pl.scan_parquet(f'./all_features/{GENERATE_FOR}_user_item_int_features.pqt')\n",
    "\n",
    "val_df = pl.scan_parquet(val_path)\n",
    "    \n",
    "for type_str in tqdm(list(type_labels.keys())):\n",
    "    \n",
    "    covisit_feature_df = pl.scan_parquet(f'../raw_data/{GENERATE_FOR}_covisitation_features/covisitation_features_{type_str}_{CANDIDATE_COUNT}candidates.pqt')\n",
    "    all_clicks_covisit_feature_df = pl.scan_parquet(f'../raw_data/{GENERATE_FOR}_covisitation_features/all_clicks_covisitation_features.pqt')\n",
    "    all_cart_covisit_feature_df = pl.scan_parquet(f'../raw_data/{GENERATE_FOR}_covisitation_features/all_carts_orders_covisitation_features.pqt')\n",
    "    all_buy2buy_covisit_feature_df = pl.scan_parquet(f'../raw_data/{GENERATE_FOR}_covisitation_features/all_buy2buy_covisitation_features.pqt')\n",
    "    \n",
    "#     ppmi_feature_df = pl.scan_parquet(f'../raw_data/{GENERATE_FOR}_ppmi_features/ppmi_features_{type_str}_{CANDIDATE_COUNT}candidates.pqt')\n",
    "    ppmi_all_feature_df = pl.scan_parquet(f'../raw_data/{GENERATE_FOR}_ppmi_all_history_features/ppmi_all_history_features_{type_str}_{CANDIDATE_COUNT}candidates.pqt')\n",
    "\n",
    "    \n",
    "#     w2v_feature_df = pl.scan_parquet(f'../raw_data/{GENERATE_FOR}_word2vec_features/word2vec_features_{type_str}_{CANDIDATE_COUNT}candidates.pqt')\n",
    "\n",
    "    pf = ParquetFile(f\"./candidate_data/{GENERATE_FOR}_{CANDIDATE_COUNT}candidates_{type_str}.parquet\")\n",
    "    chunk = 10_000_000\n",
    "    \n",
    "    total_candidate_df = 0\n",
    "    \n",
    "    \n",
    "    for batch_i, batch in tqdm(enumerate(pf.iter_batches(batch_size = chunk))):\n",
    "        candidate_df = batch.to_pandas()\n",
    "        candidate_df = pl.from_pandas(candidate_df)  \n",
    "\n",
    "        rank_repeater = np.hstack([list(range(1,CANDIDATE_COUNT+1)) for i in range(int(len(candidate_df)/CANDIDATE_COUNT))])\n",
    "        candidate_df = candidate_df.with_column(pl.Series(name=\"candidate_rank\", values=rank_repeater))\n",
    "        del rank_repeater;gc.collect()\n",
    "\n",
    "        candidate_df = candidate_df.join(covisit_feature_df, on=['session',\n",
    "                                                                 'aid'], how='left').fill_null(-1)\n",
    "        candidate_df = candidate_df.unique()\n",
    "        \n",
    "#         candidate_df = candidate_df.join(ppmi_feature_df, on=['session',\n",
    "#                                                               'aid'], how='left').fill_null(-1)\n",
    "#         candidate_df = candidate_df.unique()\n",
    "\n",
    "        candidate_df = candidate_df.join(ppmi_all_feature_df, on=['session',\n",
    "                                                              'aid'], how='left').fill_null(-1)\n",
    "        candidate_df = candidate_df.unique()\n",
    "        \n",
    "        candidate_df = candidate_df.join(all_clicks_covisit_feature_df, on=['aid'], how='left').fill_null(-1)\n",
    "        candidate_df = candidate_df.join(all_cart_covisit_feature_df, on=['aid'], how='left').fill_null(-1)\n",
    "        candidate_df = candidate_df.join(all_buy2buy_covisit_feature_df, on=['aid'], how='left').fill_null(-1)\n",
    "        \n",
    "        candidate_df = candidate_df.unique()\n",
    "\n",
    "#         candidate_df = candidate_df.join(w2v_feature_df, on=['session',\n",
    "#                                                              'aid'], how='left').fill_null(-1)\n",
    "\n",
    "        #print('Candidate Rank Features, Done...')\n",
    "        candidate_df = candidate_df.join(item_features, on='aid', how='left').fill_null(-1)\n",
    "        #print('Item Features, Done...')\n",
    "        candidate_df = candidate_df.join(user_features, on='session', how='left').fill_null(-1)\n",
    "        #print('User Features, Done...')\n",
    "        candidate_df = candidate_df.join(user_item_int_features,\n",
    "                                          on=['session', 'aid'],\n",
    "                                          how='left').fill_null(-1)\n",
    "        #print('User-Item Features, Done...')\n",
    "        tar = pd.read_parquet('./splitted_raw_data/val_labels.parquet')\n",
    "        tar = tar.loc[ tar['type'] == type_str ]\n",
    "        aids = tar.ground_truth.explode().rename('aid')\n",
    "        tar = tar[['session']]\n",
    "        tar = tar.merge(aids, left_index=True, right_index=True, how='left')\n",
    "        tar['label'] = 1\n",
    "        #print('Extract Labels, Done...')\n",
    "        \n",
    "        tar = pl.from_pandas(tar)\n",
    "        \n",
    "        candidate_df = candidate_df.join(tar, on=['session','aid'], how='left').fill_null(0)\n",
    "        candidate_df = candidate_df.unique()\n",
    "        candidate_df.write_parquet(f'./candidated_features/{GENERATE_FOR}_{type_str}_all_data_{CANDIDATE_COUNT}candidates_p{batch_i}.pqt')\n",
    "        \n",
    "        del candidate_df,tar,aids;gc.collect()\n",
    "        \n",
    "    del covisit_feature_df;gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b4d352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dff = pd.read_parquet(f'./candidated_features/{GENERATE_FOR}_clicks_all_data.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d7ffc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436c2480",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_covisitation_features(input_cand_df=candidate_df,\n",
    "                                          input_user_int_df=val_df,\n",
    "                                          input_covisit_df=covisit[0],\n",
    "                                          covisit_name=covisit[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4469576e",
   "metadata": {},
   "source": [
    "temporal feature - son x günde saatte kaç kere tıklanmış etmiş\n",
    "\n",
    "bu aid session içinde arka arkaya kaç kere aksiyon almış"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524b62ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3695.647257,
   "end_time": "2022-11-28T19:50:53.428271",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-11-28T18:49:17.781014",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
