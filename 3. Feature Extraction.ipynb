{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19803c5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-28T18:49:25.672561Z",
     "iopub.status.busy": "2022-11-28T18:49:25.671835Z",
     "iopub.status.idle": "2022-11-28T18:49:28.346781Z",
     "shell.execute_reply": "2022-11-28T18:49:28.345442Z"
    },
    "papermill": {
     "duration": 2.696152,
     "end_time": "2022-11-28T18:49:28.349900",
     "exception": false,
     "start_time": "2022-11-28T18:49:25.653748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will use RAPIDS version 22.10.00a+392.g1558403753\n",
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "VER = 6\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import os, sys, pickle, glob, gc\n",
    "from collections import Counter\n",
    "import cudf, itertools\n",
    "print('We will use RAPIDS version',cudf.__version__)\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "pandarallel.initialize(nb_workers=4, progress_bar=True, use_memory_fs=True)\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "from pyarrow.parquet import ParquetFile\n",
    "import pyarrow as pa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da36dbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory(df):\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type != object:\n",
    "            cmin = df[col].min()\n",
    "            cmax = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if cmin > np.iinfo(np.int32).min and cmax < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif cmin > np.iinfo(np.int64).min and cmax < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if cmin > np.finfo(np.float32).min and cmax < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2505537",
   "metadata": {
    "papermill": {
     "duration": 0.020472,
     "end_time": "2022-11-28T18:57:43.433117",
     "exception": false,
     "start_time": "2022-11-28T18:57:43.412645",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15a31502",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE_FOR = \"kaggle\" # \"kaggle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e70b81b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_labels = {'clicks':0, 'carts':1, 'orders':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df7c530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CANDIDATE_COUNT = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfedd66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE_FOR == \"local\":\n",
    "    train_path = \"./splitted_raw_data/train.parquet\"\n",
    "    val_path = \"./splitted_raw_data/val.parquet\"\n",
    "    \n",
    "elif GENERATE_FOR == \"kaggle\":\n",
    "    train_path = \"./splitted_raw_data/all_train.parquet\"\n",
    "    val_path = \"./splitted_raw_data/test.parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d255fb05",
   "metadata": {},
   "source": [
    "### CANDIDATE COVISIT FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "119fee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_covisitation_features(input_cand_df,\n",
    "                              input_user_int_df,\n",
    "                              input_covisit_df,\n",
    "                              covisit_name=\"clicks\",\n",
    "                              score_col=\"wgt\",\n",
    "                              scoring_name=\"covisitation\"):      \n",
    "    \n",
    "    candidates_w_covisit = input_cand_df[[\"session\", \"aid\"]].rename({\"aid\":\"aid_x\"}).\\\n",
    "    join(input_user_int_df.rename({\"aid\":\"aid_y\"})[[\"session\", \"aid_y\"]],\n",
    "         how=\"left\",\n",
    "         on=\"session\").fill_null(0).join(input_covisit_df, how=\"left\", on=[\"aid_x\", \"aid_y\"])\n",
    "\n",
    "    candidates_w_covisit = candidates_w_covisit.fill_null(0.)\n",
    "    \n",
    "    candidates_w_covisit_gby = (\n",
    "        candidates_w_covisit\n",
    "        .groupby([\"session\", \"aid_x\"])\n",
    "        .agg(\n",
    "            [\n",
    "                pl.col(score_col).max().alias(covisit_name + '_' + scoring_name + '_' + \"max\"),\n",
    "                pl.col(score_col).min().alias(covisit_name + '_' + scoring_name + '_' + \"min\"),\n",
    "                pl.col(score_col).std().alias(covisit_name + '_' + scoring_name + '_' + \"std\"),\n",
    "                pl.col(score_col).sum().alias(covisit_name + '_' + scoring_name + '_' + \"sum\"),\n",
    "                pl.col(score_col).mean().alias(covisit_name + '_' + scoring_name + '_' + \"mean\"),\n",
    "                pl.col(score_col).count().alias(covisit_name + '_' + scoring_name + '_' + \"count\"),\n",
    "            ]\n",
    "        )\n",
    "    ).sort(\"session\", reverse=False)\n",
    "\n",
    "    candidates_w_covisit_gby = candidates_w_covisit_gby.rename({\"aid_x\":\"aid\"})\n",
    "    \n",
    "    candidates_w_covisit_gby = candidates_w_covisit_gby.with_column(pl.col(\"aid\").cast(pl.Int32))\n",
    "    candidates_w_covisit_gby = candidates_w_covisit_gby.with_column(pl.col(\"session\").cast(pl.Int32)) \n",
    "    return candidates_w_covisit_gby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "977affcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidate_history_pair_score_features(input_val_df_path,\n",
    "                                                   score_df_tuples_w_names,\n",
    "                                                   score_col,\n",
    "                                                   scoring_name=\"covisitation\"):\n",
    "    \n",
    "    val_df = pl.read_parquet(input_val_df_path)\n",
    "\n",
    "    for type_str in tqdm(list(type_labels.keys())):\n",
    "\n",
    "        pf = ParquetFile(f\"./candidate_data/{GENERATE_FOR}_{CANDIDATE_COUNT}candidates_{type_str}.parquet\")\n",
    "        chunk = 10_000_000\n",
    "\n",
    "        total_candidate_df = []\n",
    "\n",
    "        for batch_i, batch in tqdm(enumerate(pf.iter_batches(batch_size = chunk))):\n",
    "            candidate_df = batch.to_pandas()\n",
    "            candidate_df = pl.from_pandas(candidate_df)\n",
    "\n",
    "            candidate_df = candidate_df.with_column(pl.col(\"aid\").cast(pl.Int32))\n",
    "            candidate_df = candidate_df.with_column(pl.col(\"session\").cast(pl.Int32)) \n",
    "\n",
    "            val_df = val_df.with_column(pl.col(\"aid\").cast(pl.Int32))\n",
    "            val_df = val_df.with_column(pl.col(\"session\").cast(pl.Int32))\n",
    "\n",
    "            for covisit in score_df_tuples_w_names:\n",
    "                covisit[0] = covisit[0].with_column(pl.col(\"aid_x\").cast(pl.Int32))\n",
    "                covisit[0] = covisit[0].with_column(pl.col(\"aid_y\").cast(pl.Int32))\n",
    "\n",
    "                candidate_df = candidate_df.join(\n",
    "                    get_covisitation_features(input_cand_df=candidate_df,\n",
    "                                              input_user_int_df=val_df,\n",
    "                                              input_covisit_df=covisit[0],\n",
    "                                              covisit_name=covisit[1],\n",
    "                                              score_col=score_col,\n",
    "                                              scoring_name=scoring_name),\n",
    "                    how=\"left\",\n",
    "                    on=[\"session\", \"aid\"])\n",
    "\n",
    "            candidate_df = candidate_df.with_column(pl.col(\"aid\").cast(pl.Int64))\n",
    "            candidate_df = candidate_df.with_column(pl.col(\"session\").cast(pl.Int64))         \n",
    "\n",
    "            total_candidate_df.append(candidate_df)\n",
    "\n",
    "            del candidate_df\n",
    "\n",
    "        total_candidate_df = pl.concat(total_candidate_df)    \n",
    "        \n",
    "        total_candidate_df = total_candidate_df.with_columns([pl.col(total_candidate_df.columns[2:]).cast(pl.Float32),])\n",
    "        total_candidate_df.write_parquet(f'../raw_data/{GENERATE_FOR}_{scoring_name}_features/{scoring_name}_features_{type_str}_{CANDIDATE_COUNT}candidates.pqt')\n",
    "\n",
    "        del total_candidate_df;gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b24d90",
   "metadata": {},
   "source": [
    "### Covisitation pair 'wgt' features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9fdc52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading clicks covisitation...\n",
      "Reading carts-orders covisitation...\n",
      "Reading buy2buy covisitation...\n"
     ]
    }
   ],
   "source": [
    "DISK_PIECES = 4\n",
    "\n",
    "print(\"Reading clicks covisitation...\")\n",
    "clicks_cov_df = pl.from_pandas(pd.concat([pd.read_parquet(f'../raw_data/{GENERATE_FOR}_covisitation/{GENERATE_FOR}_top_{CANDIDATE_COUNT}_clicks_v{VER}_{k}.pqt') for k in range(0, DISK_PIECES)], ignore_index=True))\n",
    "print(\"Reading carts-orders covisitation...\")\n",
    "carts_orders_cov_df = pl.from_pandas(pd.concat([pd.read_parquet(f'../raw_data/{GENERATE_FOR}_covisitation/{GENERATE_FOR}_top_{CANDIDATE_COUNT}_carts_orders_v{VER}_{k}.pqt') for k in range(0, DISK_PIECES)], ignore_index=True))\n",
    "print(\"Reading buy2buy covisitation...\")\n",
    "buy2buy_cov_df = pl.from_pandas(pd.concat([pd.read_parquet(f'../raw_data/{GENERATE_FOR}_covisitation/{GENERATE_FOR}_top_{CANDIDATE_COUNT}_buy2buy_v{VER}_{k}.pqt') for k in range(0, 1)], ignore_index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bda6f7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_covisits_features(input_covisit_df,\n",
    "                         score_col,\n",
    "                         covisit_name):\n",
    "    aid_cov_feat_df = (\n",
    "        clicks_cov_df\n",
    "        .groupby([\"aid_x\"])\n",
    "        .agg(\n",
    "            [\n",
    "                pl.col(score_col).max().alias(covisit_name + '_' + score_col + '_' + \"max\"),\n",
    "                pl.col(score_col).min().alias(covisit_name + '_' + score_col + '_' + \"min\"),\n",
    "                pl.col(score_col).std().alias(covisit_name + '_' + score_col + '_' + \"std\"),\n",
    "                pl.col(score_col).sum().alias(covisit_name + '_' + score_col + '_' + \"sum\"),\n",
    "                pl.col(score_col).mean().alias(covisit_name + '_' + score_col + '_' + \"mean\"),\n",
    "                pl.col(score_col).count().alias(covisit_name + '_' + score_col + '_' + \"count\"),\n",
    "            ]\n",
    "        )\n",
    "    ).sort(\"aid_x\", reverse=False).rename({\"aid_x\":\"aid\"})\n",
    "    \n",
    "    aid_cov_feat_df = aid_cov_feat_df.with_columns([pl.col([\"aid\"]).cast(pl.Int64)])\n",
    "\n",
    "    aid_cov_feat_df.write_parquet(f'../raw_data/{GENERATE_FOR}_covisitation_features/{covisit_name}_covisitation_features.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57d205bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "513bd56371f349af92df81d4a2f004dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score_df_tuples_w_names = [[clicks_cov_df, \"all_clicks\"],\n",
    "                           [carts_orders_cov_df, \"all_carts_orders\"],\n",
    "                           [buy2buy_cov_df, \"all_buy2buy\"]]\n",
    "\n",
    "for covisit_tuple in tqdm(score_df_tuples_w_names):\n",
    "    all_covisits_features(input_covisit_df=covisit_tuple[0],\n",
    "                          score_col=\"wgt\",\n",
    "                          covisit_name=covisit_tuple[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d15db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df_tuples_w_names = [[clicks_cov_df, \"clicks\"],\n",
    "                           [carts_orders_cov_df, \"carts_orders\"],\n",
    "                           [buy2buy_cov_df, \"buy2buy\"]]\n",
    "\n",
    "generate_candidate_history_pair_score_features(input_val_df_path=val_path,\n",
    "                                               score_df_tuples_w_names=score_df_tuples_w_names,\n",
    "                                               score_col=\"wgt\",\n",
    "                                               scoring_name=\"covisitation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baf8c84",
   "metadata": {},
   "source": [
    "### Word2Vec pair 'similarity' features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2b8e49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading clicks w2v...\n",
      "Reading carts-orders w2v...\n",
      "Reading buy2buy w2v...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87bd4c4e6f804f6490c902e930756441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea2bb49f1c34ba3a1ebb1b2edaebd7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61dab9028e074e2e80bc2ee52feda9a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb68d865b8e848c186367ab69e3d50a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Reading clicks w2v...\")\n",
    "clicks_cov_df = pl.scan_parquet(f'./all_features/{GENERATE_FOR}_top_{CANDIDATE_COUNT}_clicks_w2v_similarities.pqt')\n",
    "clicks_cov_df = clicks_cov_df.rename({\"similarity\":\"w2v_similarity\"})\n",
    "print(\"Reading carts-orders w2v...\")\n",
    "carts_orders_cov_df = pl.scan_parquet(f'./all_features/{GENERATE_FOR}_top_{CANDIDATE_COUNT}_carts_w2v_similarities.pqt')\n",
    "carts_orders_cov_df = carts_orders_cov_df.rename({\"similarity\":\"w2v_similarity\"})\n",
    "print(\"Reading buy2buy w2v...\")\n",
    "buy2buy_cov_df = pl.scan_parquet(f'./all_features/{GENERATE_FOR}_top_{CANDIDATE_COUNT}_buy2buy_w2v_similarities.pqt')\n",
    "buy2buy_cov_df = buy2buy_cov_df.rename({\"similarity\":\"w2v_similarity\"})\n",
    "\n",
    "score_df_tuples_w_names = [[clicks_cov_df, \"clicks\"],\n",
    "                           [carts_orders_cov_df, \"carts_orders\"],\n",
    "                           [buy2buy_cov_df, \"buy2buy\"]]\n",
    "\n",
    "generate_candidate_history_pair_score_features(input_val_df_path=val_path,\n",
    "                                               score_df_tuples_w_names=score_df_tuples_w_names,\n",
    "                                               score_col=\"w2v_similarity\",\n",
    "                                               scoring_name=\"word2vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988d59c2",
   "metadata": {},
   "source": [
    "## Generating Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68a2d28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_datetime_features(input_df):\n",
    "    input_df[\"datetime\"] = pd.to_datetime(input_df.ts + (2 * 60 * 60), unit='s')\n",
    "    input_df[\"hour\"] = input_df[\"datetime\"].dt.hour\n",
    "    input_df[\"dayofweek\"] = input_df[\"datetime\"].dt.dayofweek\n",
    "    input_df[\"is_weekend\"] = (input_df[\"dayofweek\"]>4).astype(int)\n",
    "    return input_df\n",
    "\n",
    "def datetime_aggregator(input_df,\n",
    "                        group_cols=[],\n",
    "                        wanted_cols=[]):\n",
    "    return_df = input_df.groupby(group_cols).agg(\n",
    "        {'hour':['mean', 'std'],\n",
    "         'dayofweek':['mean', 'std'],\n",
    "         'is_weekend':['mean']\n",
    "        })\n",
    "    return_df.columns = ['_'.join(group_cols) + '_' +  '_'.join(col) for col in return_df.columns]\n",
    "    return return_df\n",
    "\n",
    "def type_distribution_aggregator(input_df, \n",
    "                                 group_cols=[]):\n",
    "    return_df = input_df.groupby(group_cols)['type'].value_counts(normalize=True)\n",
    "    return_df = return_df.unstack('type')\n",
    "    return_df.columns = ['_'.join(group_cols) + '_type' + str(col) + \"_mean\" for col in return_df.columns]\n",
    "    return return_df\n",
    "\n",
    "def existence_amount_aggregator(input_df,\n",
    "                                 group_cols=[],\n",
    "                                wanted_cols=[]):\n",
    "    \n",
    "    return_df = input_df.groupby(group_cols).agg({col:[\"count\"] for col in wanted_cols})\n",
    "    return_df.columns = ['_'.join(group_cols) + '_' +  '_'.join(col) for col in return_df.columns]\n",
    "    \n",
    "    count_cols = list(return_df.columns)\n",
    "    \n",
    "    for count_col in count_cols:  \n",
    "        return_df[count_col.replace(\"count\", \"existed\")] = (return_df[count_col]>0).astype(int)\n",
    "        return_df[count_col.replace(\"count\", \"existed_multiple\")] = (return_df[count_col]>1).astype(int)\n",
    "#         return_df[count_col.replace(\"count\", \"existed_times\")] = (return_df[count_col]).astype(int)\n",
    "    \n",
    "    return_df = return_df[[col for col in return_df.columns if (\"count\" not in col)]]\n",
    "    \n",
    "    return return_df\n",
    "\n",
    "def nunique_aggregator(input_df,\n",
    "                       group_cols=[],\n",
    "                       wanted_cols=[]):\n",
    "    \n",
    "    return_df = input_df.groupby(group_cols).agg({col:[\"nunique\"] for col in wanted_cols})\n",
    "    return_df.columns = ['_'.join(group_cols) + '_' +  '_'.join(col) for col in return_df.columns]\n",
    "\n",
    "    return return_df\n",
    "\n",
    "def is_last_aid_of_the_session(input_df,\n",
    "                               group_cols=[\"session\", \"aid\"],\n",
    "                               wanted_cols=[]\n",
    "                              ):\n",
    "    \n",
    "    return_df = input_df[group_cols].copy()\n",
    "    return_df[\"is_aid_interacted_last\"] = 0\n",
    "    return_df.loc[return_df.session.shift(-1) != return_df.session, \"is_aid_interacted_last\"] = 1\n",
    "    return_df = return_df.groupby(group_cols).agg({\"is_aid_interacted_last\":[\"max\"]})\n",
    "    return_df.columns = [\"is_aid_interacted_last_in_session\"]\n",
    "    return return_df\n",
    "\n",
    "def session_len(input_df,\n",
    "                group_cols=[\"session\"],\n",
    "                wanted_cols=[],\n",
    "                return_min_max=False\n",
    "               ):\n",
    "    return_df = input_df[group_cols + [\"ts\"]].copy()\n",
    "    return_df = return_df.groupby(group_cols).agg({\"ts\":[\"min\", \"max\"]})\n",
    "    return_df.columns = [\"session_start\", \"session_end\"]\n",
    "    return_df[\"session_len\"] = return_df[\"session_end\"] - return_df[\"session_start\"]\n",
    "    \n",
    "    if return_min_max:\n",
    "        return return_df\n",
    "    else:\n",
    "        return return_df[[\"session_len\"]]\n",
    "\n",
    "def aid_session_ts_offsets(input_df,\n",
    "                group_cols=[\"session\", \"aid\"],\n",
    "                wanted_cols=[]):\n",
    "    session_lens = session_len(input_df,\n",
    "                               return_min_max=True).reset_index()\n",
    "    return_df = input_df[group_cols + [\"ts\"]].copy()\n",
    "    return_df = return_df.groupby(group_cols).agg({\"ts\":[\"last\"]})\n",
    "    return_df.columns = [\"session_aid_last_ts\"]\n",
    "    return_df.reset_index(inplace=True)\n",
    "    return_df = return_df.merge(session_lens, how=\"left\", on=\"session\")\n",
    "    return_df[\"aid_ts_session_end_offset\"] = return_df[\"session_end\"] - return_df[\"session_aid_last_ts\"]\n",
    "    return_df[\"aid_ts_session_start_offset\"] = return_df[\"session_aid_last_ts\"] - return_df[\"session_start\"]\n",
    "\n",
    "    return_df = return_df[group_cols + [\"aid_ts_session_end_offset\", \"aid_ts_session_start_offset\"]].set_index(group_cols)\n",
    "    return return_df\n",
    "\n",
    "def type_based_aggregator(input_df,\n",
    "                          group_cols=[],\n",
    "                          wanted_cols=[],\n",
    "                          aggregators=[]):\n",
    "    type_dfs = []\n",
    "    for type_id in range(3):\n",
    "        for aggregator in aggregators:\n",
    "            aggregator_df = aggregator(input_df[input_df.type==type_id].reset_index(drop=True),\n",
    "                                       group_cols=group_cols,\n",
    "                                       wanted_cols=wanted_cols)\n",
    "            aggregator_df.columns = [\"type\" + str(type_id) + \"_\" + col for col in aggregator_df.columns]\n",
    "        type_dfs.append(aggregator_df)\n",
    "        \n",
    "    return pd.concat(type_dfs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f75f59fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>aid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11098528</td>\n",
       "      <td>11830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11098528</td>\n",
       "      <td>588923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11098528</td>\n",
       "      <td>1732105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11098528</td>\n",
       "      <td>571762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11098528</td>\n",
       "      <td>884502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999995</th>\n",
       "      <td>11198527</td>\n",
       "      <td>136296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999996</th>\n",
       "      <td>11198527</td>\n",
       "      <td>188979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999997</th>\n",
       "      <td>11198527</td>\n",
       "      <td>219483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999998</th>\n",
       "      <td>11198527</td>\n",
       "      <td>256160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999999</th>\n",
       "      <td>11198527</td>\n",
       "      <td>310546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          session      aid\n",
       "0        11098528    11830\n",
       "1        11098528   588923\n",
       "2        11098528  1732105\n",
       "3        11098528   571762\n",
       "4        11098528   884502\n",
       "...           ...      ...\n",
       "9999995  11198527   136296\n",
       "9999996  11198527   188979\n",
       "9999997  11198527   219483\n",
       "9999998  11198527   256160\n",
       "9999999  11198527   310546\n",
       "\n",
       "[10000000 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b0af8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>aid</th>\n",
       "      <th>ts</th>\n",
       "      <th>type</th>\n",
       "      <th>datetime</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11098528</td>\n",
       "      <td>11830</td>\n",
       "      <td>1661119200</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-08-22 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11098529</td>\n",
       "      <td>1105029</td>\n",
       "      <td>1661119200</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-08-22 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11098530</td>\n",
       "      <td>264500</td>\n",
       "      <td>1661119200</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-08-22 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11098530</td>\n",
       "      <td>264500</td>\n",
       "      <td>1661119288</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-08-22 00:01:28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11098530</td>\n",
       "      <td>409236</td>\n",
       "      <td>1661119369</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-08-22 00:02:49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7683572</th>\n",
       "      <td>12899774</td>\n",
       "      <td>33035</td>\n",
       "      <td>1661723968</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-08-28 23:59:28</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7683573</th>\n",
       "      <td>12899775</td>\n",
       "      <td>1743151</td>\n",
       "      <td>1661723970</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-08-28 23:59:30</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7683574</th>\n",
       "      <td>12899776</td>\n",
       "      <td>548599</td>\n",
       "      <td>1661723972</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-08-28 23:59:32</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7683575</th>\n",
       "      <td>12899777</td>\n",
       "      <td>384045</td>\n",
       "      <td>1661723976</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-08-28 23:59:36</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7683576</th>\n",
       "      <td>12899778</td>\n",
       "      <td>561560</td>\n",
       "      <td>1661723983</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-08-28 23:59:43</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7683577 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          session      aid          ts  type            datetime  hour  \\\n",
       "0        11098528    11830  1661119200     0 2022-08-22 00:00:00     0   \n",
       "1        11098529  1105029  1661119200     0 2022-08-22 00:00:00     0   \n",
       "2        11098530   264500  1661119200     0 2022-08-22 00:00:00     0   \n",
       "3        11098530   264500  1661119288     0 2022-08-22 00:01:28     0   \n",
       "4        11098530   409236  1661119369     0 2022-08-22 00:02:49     0   \n",
       "...           ...      ...         ...   ...                 ...   ...   \n",
       "7683572  12899774    33035  1661723968     0 2022-08-28 23:59:28    23   \n",
       "7683573  12899775  1743151  1661723970     0 2022-08-28 23:59:30    23   \n",
       "7683574  12899776   548599  1661723972     0 2022-08-28 23:59:32    23   \n",
       "7683575  12899777   384045  1661723976     0 2022-08-28 23:59:36    23   \n",
       "7683576  12899778   561560  1661723983     0 2022-08-28 23:59:43    23   \n",
       "\n",
       "         dayofweek  is_weekend  \n",
       "0                0           0  \n",
       "1                0           0  \n",
       "2                0           0  \n",
       "3                0           0  \n",
       "4                0           0  \n",
       "...            ...         ...  \n",
       "7683572          6           1  \n",
       "7683573          6           1  \n",
       "7683574          6           1  \n",
       "7683575          6           1  \n",
       "7683576          6           1  \n",
       "\n",
       "[7683577 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be0b195b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_start</th>\n",
       "      <th>session_end</th>\n",
       "      <th>session_len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11098528</th>\n",
       "      <td>1661119200</td>\n",
       "      <td>1661119200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11098529</th>\n",
       "      <td>1661119200</td>\n",
       "      <td>1661119200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11098530</th>\n",
       "      <td>1661119200</td>\n",
       "      <td>1661120532</td>\n",
       "      <td>1332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11098531</th>\n",
       "      <td>1661119200</td>\n",
       "      <td>1661119746</td>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11098532</th>\n",
       "      <td>1661119201</td>\n",
       "      <td>1661119996</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12899774</th>\n",
       "      <td>1661723968</td>\n",
       "      <td>1661723968</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12899775</th>\n",
       "      <td>1661723970</td>\n",
       "      <td>1661723970</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12899776</th>\n",
       "      <td>1661723972</td>\n",
       "      <td>1661723972</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12899777</th>\n",
       "      <td>1661723976</td>\n",
       "      <td>1661723976</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12899778</th>\n",
       "      <td>1661723983</td>\n",
       "      <td>1661723983</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1801251 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_start  session_end  session_len\n",
       "session                                          \n",
       "11098528     1661119200   1661119200            0\n",
       "11098529     1661119200   1661119200            0\n",
       "11098530     1661119200   1661120532         1332\n",
       "11098531     1661119200   1661119746          546\n",
       "11098532     1661119201   1661119996          795\n",
       "...                 ...          ...          ...\n",
       "12899774     1661723968   1661723968            0\n",
       "12899775     1661723970   1661723970            0\n",
       "12899776     1661723972   1661723972            0\n",
       "12899777     1661723976   1661723976            0\n",
       "12899778     1661723983   1661723983            0\n",
       "\n",
       "[1801251 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_len(val_df,\n",
    "                group_cols=[\"session\"],\n",
    "                wanted_cols=[],\n",
    "                return_min_max=True\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ede33468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is read!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m user_item_int_df \u001b[38;5;241m=\u001b[39m val_df    \n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData is read!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mk\u001b[49m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m############\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# item_features = item_df.groupby('aid').agg({'aid':['count'], 'session':['nunique']})\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# item_features.columns = ['aid_' + \"_\".join(col) for col in item_features.columns]\u001b[39;00m\n\u001b[1;32m     19\u001b[0m item_features \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#     item_features,\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     existence_amount_aggregator(item_df,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m                                        existence_amount_aggregator])\n\u001b[1;32m     37\u001b[0m ], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'k' is not defined"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_parquet(train_path)\n",
    "val_df = pd.read_parquet(val_path)\n",
    "\n",
    "train_df = generate_datetime_features(train_df)\n",
    "val_df = generate_datetime_features(val_df)\n",
    "\n",
    "item_df = pd.concat([train_df,val_df], ignore_index=True)\n",
    "user_df = val_df\n",
    "user_item_int_df = val_df    \n",
    "\n",
    "print(\"Data is read!\")\n",
    "\n",
    "print(k)\n",
    "############\n",
    "\n",
    "# item_features = item_df.groupby('aid').agg({'aid':['count'], 'session':['nunique']})\n",
    "# item_features.columns = ['aid_' + \"_\".join(col) for col in item_features.columns]\n",
    "\n",
    "item_features = pd.concat([\n",
    "#     item_features,\n",
    "    existence_amount_aggregator(item_df,\n",
    "                                group_cols=[\"aid\"],\n",
    "                                wanted_cols=[\"session\", \"aid\"]),\n",
    "    nunique_aggregator(item_df,\n",
    "                       group_cols=[\"aid\"],\n",
    "                       wanted_cols=[\"session\"]),\n",
    "    datetime_aggregator(item_df,\n",
    "                        group_cols=[\"aid\"]),\n",
    "    type_distribution_aggregator(item_df,\n",
    "                                 group_cols=[\"aid\"]),\n",
    "    type_based_aggregator(item_df,\n",
    "                          group_cols=[\"aid\"],\n",
    "                          wanted_cols=[\"aid\", \"session\"],\n",
    "                          aggregators=[datetime_aggregator,\n",
    "                                       nunique_aggregator,\n",
    "                                       existence_amount_aggregator])\n",
    "], axis=1)\n",
    "\n",
    "item_features = reduce_memory(item_features)\n",
    "\n",
    "item_features.to_parquet(f'./all_features/{GENERATE_FOR}_item_features.pqt')\n",
    "\n",
    "print(\"Item features are created!\")\n",
    "\n",
    "############\n",
    "\n",
    "# user_features = user_df.groupby('session').agg({'session':['count'], 'aid':['nunique']})\n",
    "\n",
    "# user_features.columns = ['session_' + \"_\".join(col) for col in user_features.columns]\n",
    "\n",
    "user_features = pd.concat([\n",
    "#     user_features,\n",
    "    existence_amount_aggregator(user_df,\n",
    "                                group_cols=[\"session\"],\n",
    "                                wanted_cols=[\"session\", \"aid\"]),\n",
    "    session_len(user_df),\n",
    "#     nunique_aggregator(user_df,\n",
    "#                        group_cols=[\"session\"],\n",
    "#                        wanted_cols=[\"aid\"]),\n",
    "    datetime_aggregator(user_df,\n",
    "                        group_cols=[\"session\"]),\n",
    "    type_distribution_aggregator(user_df,\n",
    "                                 group_cols=[\"session\"]),\n",
    "    type_based_aggregator(user_df,\n",
    "                          group_cols=[\"session\"],\n",
    "                          wanted_cols=[\"aid\", \"session\"],\n",
    "                          aggregators=[datetime_aggregator,\n",
    "                                       session_len,\n",
    "#                                        nunique_aggregator,\n",
    "                                       existence_amount_aggregator])\n",
    "], axis=1)\n",
    "\n",
    "user_features = reduce_memory(user_features)\n",
    "\n",
    "user_features.to_parquet(f'./all_features/{GENERATE_FOR}_user_features.pqt')\n",
    "\n",
    "print(\"User features are created!\")\n",
    "\n",
    "############\n",
    "\n",
    "# user_item_int_features = user_item_int_df.groupby(['session', 'aid']).agg({'aid':['count']})\n",
    "\n",
    "# user_item_int_features.columns = ['session_aid_' + \"_\".join(col) for col in user_item_int_features.columns]\n",
    "\n",
    "user_item_int_features = pd.concat([\n",
    "#     user_item_int_features,\n",
    "    existence_amount_aggregator(user_item_int_df,\n",
    "                                group_cols=[\"session\", \"aid\"],\n",
    "                                wanted_cols=[\"aid\"]),\n",
    "    is_last_aid_of_the_session(user_item_int_df),\n",
    "    aid_session_ts_offsets(user_item_int_df),\n",
    "#     nunique_aggregator(user_df,\n",
    "#                        group_cols=[\"session\"],\n",
    "#                        wanted_cols=[\"aid\"]),\n",
    "    datetime_aggregator(user_item_int_df,\n",
    "                        group_cols=['session', 'aid']),\n",
    "    type_distribution_aggregator(user_item_int_df,\n",
    "                                 group_cols=['session', 'aid']),\n",
    "    type_based_aggregator(user_item_int_df,\n",
    "                          group_cols=['session', 'aid'],\n",
    "                          wanted_cols=[\"aid\"],\n",
    "                          aggregators=[datetime_aggregator,\n",
    "                                       is_last_aid_of_the_session,\n",
    "                                       aid_session_ts_offsets,\n",
    "#                                        nunique_aggregator,\n",
    "                                       existence_amount_aggregator])\n",
    "], axis=1)\n",
    "\n",
    "user_item_int_features = reduce_memory(user_item_int_features)\n",
    "\n",
    "user_item_int_features.to_parquet(f'./all_features/{GENERATE_FOR}_user_item_int_features.pqt')\n",
    "\n",
    "print(\"User-Item Interaction features are created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a360283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del item_features, user_features, user_item_int_features\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a850637",
   "metadata": {},
   "outputs": [],
   "source": [
    "del item_df, train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03248e26",
   "metadata": {},
   "source": [
    "## Merging Features w/ Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36ce29ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading item features...\n",
      "Reading user features...\n",
      "Reading user-item interaction features...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e591bf47fa744219a0a6ee9d4ca842d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e359d2c172654ad4a03a9b3d9d503a56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 10000000\n",
      "2 10000000\n",
      "3 10000000\n",
      "4 10000000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 68\u001b[0m\n\u001b[1;32m     66\u001b[0m candidate_df \u001b[38;5;241m=\u001b[39m candidate_df\u001b[38;5;241m.\u001b[39mjoin(tar, on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msession\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maid\u001b[39m\u001b[38;5;124m'\u001b[39m], how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfill_null(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;28mlen\u001b[39m(candidate_df))\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mk\u001b[49m)\n\u001b[1;32m     69\u001b[0m candidate_df\u001b[38;5;241m.\u001b[39mwrite_parquet(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./candidated_features/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mGENERATE_FOR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_all_data_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCANDIDATE_COUNT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mcandidates_p\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_i\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pqt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m candidate_df,tar,aids;gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'k' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Reading item features...\")\n",
    "item_features = pl.scan_parquet(f'./all_features/{GENERATE_FOR}_item_features.pqt')\n",
    "print(\"Reading user features...\")\n",
    "user_features = pl.scan_parquet(f'./all_features/{GENERATE_FOR}_user_features.pqt')\n",
    "print(\"Reading user-item interaction features...\")\n",
    "user_item_int_features = pl.scan_parquet(f'./all_features/{GENERATE_FOR}_user_item_int_features.pqt')\n",
    "\n",
    "val_df = pl.scan_parquet(val_path)\n",
    "    \n",
    "for type_str in tqdm(list(type_labels.keys())[-1:]):\n",
    "    \n",
    "    covisit_feature_df = pl.scan_parquet(f'../raw_data/{GENERATE_FOR}_covisitation_features/covisitation_features_{type_str}_{CANDIDATE_COUNT}candidates.pqt')\n",
    "    all_clicks_covisit_feature_df = pl.scan_parquet(f'../raw_data/{GENERATE_FOR}_covisitation_features/all_clicks_covisitation_features.pqt')\n",
    "    all_cart_covisit_feature_df = pl.scan_parquet(f'../raw_data/{GENERATE_FOR}_covisitation_features/all_carts_orders_covisitation_features.pqt')\n",
    "    all_buy2buy_covisit_feature_df = pl.scan_parquet(f'../raw_data/{GENERATE_FOR}_covisitation_features/all_buy2buy_covisitation_features.pqt')\n",
    "    \n",
    "    \n",
    "#     w2v_feature_df = pl.scan_parquet(f'../raw_data/{GENERATE_FOR}_word2vec_features/word2vec_features_{type_str}_{CANDIDATE_COUNT}candidates.pqt')\n",
    "\n",
    "    pf = ParquetFile(f\"./candidate_data/{GENERATE_FOR}_{CANDIDATE_COUNT}candidates_{type_str}.parquet\")\n",
    "    chunk = 10_000_000\n",
    "    \n",
    "    total_candidate_df = 0\n",
    "    \n",
    "    \n",
    "    for batch_i, batch in tqdm(enumerate(pf.iter_batches(batch_size = chunk))):\n",
    "        candidate_df = batch.to_pandas()\n",
    "        candidate_df = pl.from_pandas(candidate_df)  \n",
    "\n",
    "        rank_repeater = np.hstack([list(range(1,CANDIDATE_COUNT+1)) for i in range(int(len(candidate_df)/CANDIDATE_COUNT))])\n",
    "        candidate_df = candidate_df.with_column(pl.Series(name=\"candidate_rank\", values=rank_repeater))\n",
    "        del rank_repeater;gc.collect()\n",
    "\n",
    "        candidate_df = candidate_df.join(covisit_feature_df, on=['session',\n",
    "                                                                 'aid'], how='left').fill_null(-1)\n",
    "        candidate_df = candidate_df.unique()\n",
    "\n",
    "        candidate_df = candidate_df.join(all_clicks_covisit_feature_df, on=['aid'], how='left').fill_null(-1)\n",
    "        candidate_df = candidate_df.join(all_cart_covisit_feature_df, on=['aid'], how='left').fill_null(-1)\n",
    "        candidate_df = candidate_df.join(all_buy2buy_covisit_feature_df, on=['aid'], how='left').fill_null(-1)\n",
    "\n",
    "#         candidate_df = candidate_df.join(w2v_feature_df, on=['session',\n",
    "#                                                              'aid'], how='left').fill_null(-1)\n",
    "\n",
    "        #print('Candidate Rank Features, Done...')\n",
    "        candidate_df = candidate_df.join(item_features, on='aid', how='left').fill_null(-1)\n",
    "        #print('Item Features, Done...')\n",
    "        candidate_df = candidate_df.join(user_features, on='session', how='left').fill_null(-1)\n",
    "        #print('User Features, Done...')\n",
    "        candidate_df = candidate_df.join(user_item_int_features,\n",
    "                                          on=['session', 'aid'],\n",
    "                                          how='left').fill_null(-1)\n",
    "        #print('User-Item Features, Done...')\n",
    "        tar = pd.read_parquet('./splitted_raw_data/val_labels.parquet')\n",
    "        tar = tar.loc[ tar['type'] == type_str ]\n",
    "        aids = tar.ground_truth.explode().rename('aid')\n",
    "        tar = tar[['session']]\n",
    "        tar = tar.merge(aids, left_index=True, right_index=True, how='left')\n",
    "        tar['label'] = 1\n",
    "        #print('Extract Labels, Done...')\n",
    "        \n",
    "        tar = pl.from_pandas(tar)\n",
    "        \n",
    "        candidate_df = candidate_df.join(tar, on=['session','aid'], how='left').fill_null(0)\n",
    "        candidate_df.write_parquet(f'./candidated_features/{GENERATE_FOR}_{type_str}_all_data_{CANDIDATE_COUNT}candidates_p{batch_i}.pqt')\n",
    "        \n",
    "        del candidate_df,tar,aids;gc.collect()\n",
    "        \n",
    "    del covisit_feature_df;gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b4d352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dff = pd.read_parquet(f'./candidated_features/{GENERATE_FOR}_clicks_all_data.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d7ffc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436c2480",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_covisitation_features(input_cand_df=candidate_df,\n",
    "                                          input_user_int_df=val_df,\n",
    "                                          input_covisit_df=covisit[0],\n",
    "                                          covisit_name=covisit[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4469576e",
   "metadata": {},
   "source": [
    "temporal feature - son x günde saatte kaç kere tıklanmış etmiş\n",
    "\n",
    "bu aid session içinde arka arkaya kaç kere aksiyon almış"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524b62ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3695.647257,
   "end_time": "2022-11-28T19:50:53.428271",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-11-28T18:49:17.781014",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
