{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.00373,
     "end_time": "2022-11-10T16:03:20.9748",
     "exception": false,
     "start_time": "2022-11-10T16:03:20.97107",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 1 - Candidate Generation with RAPIDS\n",
    "For candidate generation, we build three co-visitation matrices. One computes the popularity of cart/order given a user's previous click/cart/order. We apply type weighting to this matrix. One computes the popularity of cart/order given a user's previous cart/order. We call this \"buy2buy\" matrix. One computes the popularity of clicks given a user previously click/cart/order.  We apply time weighting to this matrix. We will use RAPIDS cuDF GPU to compute these matrices quickly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-11T20:05:09.707278Z",
     "iopub.status.busy": "2023-01-11T20:05:09.706930Z",
     "iopub.status.idle": "2023-01-11T20:05:12.678295Z",
     "shell.execute_reply": "2023-01-11T20:05:12.677361Z",
     "shell.execute_reply.started": "2023-01-11T20:05:09.707200Z"
    },
    "papermill": {
     "duration": 3.036143,
     "end_time": "2022-11-10T16:03:24.014816",
     "exception": false,
     "start_time": "2022-11-10T16:03:20.978673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "VER = 10\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import os, sys, pickle, glob, gc\n",
    "from collections import Counter\n",
    "import cudf, itertools\n",
    "print('We will use RAPIDS version',cudf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-11T20:05:12.685244Z",
     "iopub.status.busy": "2023-01-11T20:05:12.682909Z",
     "iopub.status.idle": "2023-01-11T20:05:12.709824Z",
     "shell.execute_reply": "2023-01-11T20:05:12.708848Z",
     "shell.execute_reply.started": "2023-01-11T20:05:12.685207Z"
    }
   },
   "outputs": [],
   "source": [
    "MODE = \"kaggle\" # \"kaggle\"\n",
    "\n",
    "if MODE == \"kaggle\":\n",
    "    readpath = '../input/otto-chunk-data-inparquet-format/*_parquet/*'\n",
    "\n",
    "elif MODE == \"local\":\n",
    "    readpath = '/kaggle/input/otto-validation/*_parquet/*'\n",
    "\n",
    "    \n",
    "files = glob.glob(readpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-01-11T20:05:12.711937Z",
     "iopub.status.busy": "2023-01-11T20:05:12.711294Z",
     "iopub.status.idle": "2023-01-11T20:06:14.773737Z",
     "shell.execute_reply": "2023-01-11T20:06:14.772751Z",
     "shell.execute_reply.started": "2023-01-11T20:05:12.711900Z"
    },
    "papermill": {
     "duration": 0.063943,
     "end_time": "2022-11-10T16:03:24.091816",
     "exception": false,
     "start_time": "2022-11-10T16:03:24.027873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CACHE FUNCTIONS\n",
    "def read_file(f):\n",
    "    return cudf.DataFrame( data_cache[f] )\n",
    "\n",
    "def read_file_to_cache(f):\n",
    "    df = pd.read_parquet(f)\n",
    "    df.ts = (df.ts/1000).astype('int32')\n",
    "    df['type'] = df['type'].map(type_labels).astype('int8')\n",
    "    return df\n",
    "\n",
    "# CACHE THE DATA ON CPU BEFORE PROCESSING ON GPU\n",
    "data_cache = {}\n",
    "type_labels = {'clicks':0, 'carts':1, 'orders':2}\n",
    "for f in files: data_cache[f] = read_file_to_cache(f)\n",
    "CHUNK = int( np.ceil( len(files)/6 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-11T20:06:14.776867Z",
     "iopub.status.busy": "2023-01-11T20:06:14.776489Z",
     "iopub.status.idle": "2023-01-11T20:06:14.800624Z",
     "shell.execute_reply": "2023-01-11T20:06:14.799622Z",
     "shell.execute_reply.started": "2023-01-11T20:06:14.776829Z"
    },
    "papermill": {
     "duration": 566.561189,
     "end_time": "2022-11-10T16:12:50.666123",
     "exception": false,
     "start_time": "2022-11-10T16:03:24.104934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_cooccurence_df(aidx_types = [1],\n",
    "                            aidy_types = [1],\n",
    "                            use_tail = None,\n",
    "                            time_bw_aids_threshold = None,\n",
    "                            best_k = None,\n",
    "                            type_weights = None,\n",
    "                            file_name = \"dummy\",\n",
    "                            disk_pieces = 4,\n",
    "                            read_ct_size = 5):\n",
    "\n",
    "    # CHUNK PARAMETERS\n",
    "    print(f'We will process {len(files)} files, in groups of {read_ct_size} and chunks of {CHUNK}.')\n",
    "\n",
    "    # USE SMALLEST DISK_PIECES POSSIBLE WITHOUT MEMORY ERROR\n",
    "    SIZE = 1.86e6/disk_pieces\n",
    "\n",
    "    # COMPUTE IN PARTS FOR MEMORY MANGEMENT\n",
    "    for PART in range(disk_pieces):\n",
    "        print()\n",
    "        print('### DISK PART', PART+1)\n",
    "\n",
    "        # MERGE IS FASTEST PROCESSING CHUNKS WITHIN CHUNKS\n",
    "        # => OUTER CHUNKS\n",
    "        for j in range(6):\n",
    "            a = j*CHUNK\n",
    "            b = min( (j+1)*CHUNK, len(files) )\n",
    "            print(f'Processing files {a} thru {b-1} in groups of {read_ct_size}...')\n",
    "\n",
    "            # => INNER CHUNKS\n",
    "            for k in range(a,b,read_ct_size):\n",
    "                # READ FILE\n",
    "                df = [read_file(files[k])]\n",
    "                for i in range(1,read_ct_size): \n",
    "                    if k+i<b: df.append( read_file(files[k+i]) )\n",
    "                df = cudf.concat(df,ignore_index=True,axis=0)\n",
    "                df = df.sort_values(['session','ts'], ascending=[True,False])\n",
    "                \n",
    "                aidx_df = df.loc[df['type'].isin(aidx_types)] # ONLY WANT SPECIFIC TYPES\n",
    "                aidy_df = df.loc[df['type'].isin(aidy_types)] # ONLY WANT SPECIFIC TYPES\n",
    "                del df; gc.collect()\n",
    "                \n",
    "                # USE TAIL OF SESSION\n",
    "                aidx_df = aidx_df.reset_index(drop=True)\n",
    "                aidy_df = aidy_df.reset_index(drop=True)\n",
    "                \n",
    "                if use_tail:\n",
    "                    aidx_df['n'] = aidx_df.groupby('session').cumcount()\n",
    "                    aidx_df = aidx_df.loc[aidx_df.n < use_tail].drop('n',axis=1)\n",
    "                    aidy_df['n'] = aidy_df.groupby('session').cumcount()\n",
    "                    aidy_df = aidy_df.loc[aidy_df.n < use_tail].drop('n',axis=1)\n",
    "\n",
    "                # CREATE PAIRS\n",
    "                df = aidx_df.merge(aidy_df, on='session')\n",
    "                del aidx_df, aidy_df; gc.collect()\n",
    "                df = df.loc[(df.aid_x != df.aid_y)]\n",
    "                \n",
    "                if time_bw_aids_threshold:\n",
    "                    df = df.loc[ ((df.ts_x - df.ts_y).abs() < time_bw_aids_threshold) & (df.aid_x != df.aid_y) ]\n",
    "\n",
    "                # MEMORY MANAGEMENT COMPUTE IN PARTS\n",
    "                df = df.loc[(df.aid_x >= PART*SIZE)&(df.aid_x < (PART+1)*SIZE)]\n",
    "\n",
    "                # ASSIGN WEIGHTS\n",
    "                df = df[['session', 'aid_x', 'aid_y','type_y']].drop_duplicates(['session', 'aid_x', 'aid_y', 'type_y'])\n",
    "                df['wgt'] = df.type_y.map(type_weights) if type_weights else 1\n",
    "                df = df[['aid_x','aid_y','wgt']]\n",
    "                df = df.groupby(['aid_x','aid_y']).wgt.sum()\n",
    "\n",
    "                # COMBINE INNER CHUNKS\n",
    "                if k==a: tmp2 = df\n",
    "                else: tmp2 = tmp2.add(df, fill_value=0)\n",
    "                print(k,', ',end='')\n",
    "\n",
    "            print()\n",
    "\n",
    "            # COMBINE OUTER CHUNKS\n",
    "            if a==0: tmp = tmp2\n",
    "            else: tmp = tmp.add(tmp2, fill_value=0)\n",
    "            del tmp2, df\n",
    "            gc.collect()\n",
    "\n",
    "        # CONVERT MATRIX TO DICTIONARY\n",
    "        tmp = tmp.reset_index()\n",
    "        tmp = tmp.sort_values(['aid_x','wgt'],ascending=[True,False])\n",
    "\n",
    "        # SAVE TOP 40\n",
    "        tmp = tmp.reset_index(drop=True)\n",
    "        tmp['n'] = tmp.groupby('aid_x').aid_y.cumcount()\n",
    "        if best_k:\n",
    "            tmp = tmp.loc[tmp.n<best_k].drop('n',axis=1)\n",
    "\n",
    "        # SAVE PART TO DISK (convert to pandas first uses less memory)\n",
    "        tmp.to_pandas().to_parquet(f'{MODE}_{file_name}_cooccurences_v{VER}_{PART}.pqt')\n",
    "        del tmp;gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-11T20:06:14.802780Z",
     "iopub.status.busy": "2023-01-11T20:06:14.802339Z",
     "iopub.status.idle": "2023-01-11T20:09:14.811922Z",
     "shell.execute_reply": "2023-01-11T20:09:14.810903Z",
     "shell.execute_reply.started": "2023-01-11T20:06:14.802744Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_cooccurence_df(aidx_types = [0],\n",
    "                        aidy_types = [1],\n",
    "                        use_tail = None,\n",
    "                        time_bw_aids_threshold = 24 * 60 * 60,\n",
    "                        best_k = None,\n",
    "                        type_weights = None,\n",
    "                        file_name = \"(clicks)vs(carts)\",\n",
    "                        disk_pieces = 4,\n",
    "                        read_ct_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-11T20:09:14.814052Z",
     "iopub.status.busy": "2023-01-11T20:09:14.813350Z",
     "iopub.status.idle": "2023-01-11T20:10:57.447302Z",
     "shell.execute_reply": "2023-01-11T20:10:57.446368Z",
     "shell.execute_reply.started": "2023-01-11T20:09:14.814006Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_cooccurence_df(aidx_types = [0],\n",
    "                        aidy_types = [2],\n",
    "                        use_tail = None,\n",
    "                        time_bw_aids_threshold = 24 * 60 * 60,\n",
    "                        best_k = None,\n",
    "                        type_weights = None,\n",
    "                        file_name = \"(clicks)vs(orders)\",\n",
    "                        disk_pieces = 4,\n",
    "                        read_ct_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-11T20:10:57.449324Z",
     "iopub.status.busy": "2023-01-11T20:10:57.448963Z",
     "iopub.status.idle": "2023-01-11T20:12:57.173266Z",
     "shell.execute_reply": "2023-01-11T20:12:57.172303Z",
     "shell.execute_reply.started": "2023-01-11T20:10:57.449285Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_cooccurence_df(aidx_types = [1],\n",
    "                        aidy_types = [1],\n",
    "                        use_tail = None,\n",
    "                        time_bw_aids_threshold = None,\n",
    "                        best_k = None,\n",
    "                        type_weights = None,\n",
    "                        file_name = \"(carts)vs(carts)\",\n",
    "                        disk_pieces = 4,\n",
    "                        read_ct_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-11T20:12:57.175149Z",
     "iopub.status.busy": "2023-01-11T20:12:57.174695Z",
     "iopub.status.idle": "2023-01-11T20:14:22.364628Z",
     "shell.execute_reply": "2023-01-11T20:14:22.363625Z",
     "shell.execute_reply.started": "2023-01-11T20:12:57.175112Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_cooccurence_df(aidx_types = [1],\n",
    "                        aidy_types = [2],\n",
    "                        use_tail = None,\n",
    "                        time_bw_aids_threshold = None,\n",
    "                        best_k = None,\n",
    "                        type_weights = None,\n",
    "                        file_name = \"(carts)vs(orders)\",\n",
    "                        disk_pieces = 4,\n",
    "                        read_ct_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-11T20:14:22.366616Z",
     "iopub.status.busy": "2023-01-11T20:14:22.366120Z",
     "iopub.status.idle": "2023-01-11T20:15:47.990689Z",
     "shell.execute_reply": "2023-01-11T20:15:47.989744Z",
     "shell.execute_reply.started": "2023-01-11T20:14:22.366578Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_cooccurence_df(aidx_types = [2],\n",
    "                        aidy_types = [1],\n",
    "                        use_tail = None,\n",
    "                        time_bw_aids_threshold = None,\n",
    "                        best_k = None,\n",
    "                        type_weights = None,\n",
    "                        file_name = \"(orders)vs(carts)\",\n",
    "                        disk_pieces = 4,\n",
    "                        read_ct_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-11T20:15:47.994105Z",
     "iopub.status.busy": "2023-01-11T20:15:47.993731Z",
     "iopub.status.idle": "2023-01-11T20:17:07.271785Z",
     "shell.execute_reply": "2023-01-11T20:17:07.270741Z",
     "shell.execute_reply.started": "2023-01-11T20:15:47.994069Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_cooccurence_df(aidx_types = [2],\n",
    "                        aidy_types = [2],\n",
    "                        use_tail = None,\n",
    "                        time_bw_aids_threshold = None,\n",
    "                        best_k = None,\n",
    "                        type_weights = None,\n",
    "                        file_name = \"(orders)vs(orders)\",\n",
    "                        disk_pieces = 4,\n",
    "                        read_ct_size = 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
